{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Train a Digit Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import necessary libraries\n",
    "Here is the sample code of how to import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "\n",
    "from ipywidgets import interact\n",
    "from keras import layers, Model, optimizers\n",
    "from keras.applications import VGG19\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Setup GPU’s memory policies and tensor’s behavior\n",
    "\n",
    "Here is the sample code of how to setup GPU’s memory policies and tensor’s behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices  =  tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "            tf.experimental.numpy.experimental_enable_numpy_behavior(prefer_float32 = True)\n",
    "    except RuntimeError as error:\n",
    "        print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Loading and Preprocessing\n",
    "\n",
    "Here is the sample code of how to load, preprocess, and interact with the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(60000, 64, 64, 3), (60000, 10)]\n",
      "[(10000, 64, 64, 3), (60000, 10)]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_mnist(x: object, y: object, x_new_shape: tuple) ->tuple[object, object]:\n",
    "    \"\"\"\n",
    "    @author: Vo, Huynh Quang Nguyen\n",
    "\n",
    "    Preprocess the MNIST dataset.\n",
    "\n",
    "    This function preprocess_mnist preprocesses the MNIST dataset by:\n",
    "    1. Upscaling the dimensions of the input images (from)\n",
    "    \"\"\"\n",
    "    x = x.reshape(x.shape[0], 28, 28, 1).astype('float32')\n",
    "    x = tf.image.resize(x, x_new_shape)\n",
    "    x = np.stack((x[:,:,:,0],) * 3, axis = -1) \n",
    "    x = x.astype('float32') / 255.0\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    return x, y \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, y_train = preprocess_mnist(x_train, y_train, (64,64))\n",
    "x_test, y_test= preprocess_mnist(x_test, y_test, (64,64))\n",
    "\n",
    "print([x_train.shape, y_train.shape])\n",
    "print([x_test.shape, y_train.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the model\n",
    "Here is the sample code of how to define a model using Keras functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " globavgpool (GlobalAverageP  (None, 512)              0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 4096)              2101248   \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,166,602\n",
      "Trainable params: 22,166,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def vgg19(input_shape: tuple) -> object:\n",
    "    \"\"\"\n",
    "    @author: Vo, Huynh Quang Nguyen\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape = input_shape, name = 'inputs')\n",
    "    vggmodel = VGG19(include_top = False, input_tensor = inputs, weights = 'imagenet')\n",
    "    vggmodel.trainable = True\n",
    "    x = vggmodel.output\n",
    "    x = layers.GlobalAveragePooling2D(name = 'globavgpool')(x)\n",
    "    x = layers.Dense(4096, activation = 'relu', name = 'dense1')(x)\n",
    "    outputs = layers.Dense(10, activation = 'softmax', name = 'outputs')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs, name = 'VGG19')\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.Adam(learning_rate = 0.0001), \n",
    "                  metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "vgg19 = vgg19((64,64,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the model\n",
    "\n",
    "Here is the sample code of how to train the model using `ModelCheckpoint` from Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9681\n",
      "Epoch 1: val_accuracy improved from -inf to 0.98914, saving model to weights\\VGG19_01_0.99.hdf5\n",
      "1257/1257 [==============================] - 62s 46ms/step - loss: 0.1068 - accuracy: 0.9681 - val_loss: 0.0409 - val_accuracy: 0.9891\n",
      "Epoch 2/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9870\n",
      "Epoch 2: val_accuracy improved from 0.98914 to 0.99096, saving model to weights\\VGG19_02_0.99.hdf5\n",
      "1257/1257 [==============================] - 57s 46ms/step - loss: 0.0484 - accuracy: 0.9870 - val_loss: 0.0355 - val_accuracy: 0.9910\n",
      "Epoch 3/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9917\n",
      "Epoch 3: val_accuracy did not improve from 0.99096\n",
      "1257/1257 [==============================] - 58s 46ms/step - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9902\n",
      "Epoch 4/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9912\n",
      "Epoch 4: val_accuracy did not improve from 0.99096\n",
      "1257/1257 [==============================] - 57s 46ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.0393 - val_accuracy: 0.9896\n",
      "Epoch 5/10\n",
      "1256/1257 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9927\n",
      "Epoch 5: val_accuracy improved from 0.99096 to 0.99278, saving model to weights\\VGG19_05_0.99.hdf5\n",
      "1257/1257 [==============================] - 59s 47ms/step - loss: 0.0301 - accuracy: 0.9927 - val_loss: 0.0329 - val_accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9941\n",
      "Epoch 6: val_accuracy did not improve from 0.99278\n",
      "1257/1257 [==============================] - 57s 46ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0440 - val_accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9955\n",
      "Epoch 7: val_accuracy improved from 0.99278 to 0.99283, saving model to weights\\VGG19_07_0.99.hdf5\n",
      "1257/1257 [==============================] - 57s 46ms/step - loss: 0.0210 - accuracy: 0.9955 - val_loss: 0.0309 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9942\n",
      "Epoch 8: val_accuracy did not improve from 0.99283\n",
      "1257/1257 [==============================] - 58s 46ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.0394 - val_accuracy: 0.9915\n",
      "Epoch 9/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9963\n",
      "Epoch 9: val_accuracy improved from 0.99283 to 0.99364, saving model to weights\\VGG19_09_0.99.hdf5\n",
      "1257/1257 [==============================] - 58s 46ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.0294 - val_accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "1257/1257 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9959\n",
      "Epoch 10: val_accuracy did not improve from 0.99364\n",
      "1257/1257 [==============================] - 58s 46ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.0415 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.callbacks.History at 0x1a8a7958910>, 583.7799)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_classification_model(model: object, model_name: str, X: object, Y: object, \n",
    "    metric_to_monitor: str, no_of_epochs: int, batch_size: int, validation_split_ratio: float) -> tuple[object, float]:\n",
    "    \"\"\"\n",
    "    @author: Vo, Huynh Quang Nguyen\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ###\n",
    "    weight_path = 'weights/VGG19_{epoch:02d}_{val_accuracy:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(weight_path, monitor = metric_to_monitor, \n",
    "        verbose = 1, save_best_only = True, mode = 'max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history = model.fit(X, Y, validation_split = validation_split_ratio, epochs = no_of_epochs, \n",
    "        batch_size = batch_size, callbacks = callbacks_list, verbose = 1)\n",
    "    np.save(f'{model_name}_history.npy', history.history)\n",
    "    ###\n",
    "    end_time = time.time()\n",
    "\n",
    "    training_time = round(end_time - start_time, 4)\n",
    "    return history, training_time\n",
    "\n",
    "train_classification_model(vgg19, 'VGG19', x_train, y_train, 'val_accuracy', 10, 32, 0.33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflow_latest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d1c19e37e5f6196bc516d7b965f651cc74a678b65e0e3f127f9e9132621bafc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
