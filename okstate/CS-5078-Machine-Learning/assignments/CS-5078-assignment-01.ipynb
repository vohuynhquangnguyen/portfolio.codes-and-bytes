{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36a42215",
      "metadata": {
        "id": "36a42215"
      },
      "source": [
        "# Assignment 1\n",
        "Name: Vo, Huynh Quang Nguyen\n",
        "\n",
        "CWID: A20446163"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb038e31",
      "metadata": {
        "id": "bb038e31"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afad972e",
      "metadata": {
        "id": "afad972e"
      },
      "source": [
        "### Problem 1\n",
        "Note: I used the Euclidean distance $d = \\sqrt{(x_0 - x_1)^2 + (y_0 - y_1)^2} = \\sqrt{(dx)^2 + (dy)^2}$ as a metric to implement my kDTree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afaa7ebd",
      "metadata": {
        "id": "afaa7ebd"
      },
      "outputs": [],
      "source": [
        "def Euclidean_distance(p1, p2):\n",
        "    \"\"\"\n",
        "    Compute the Euclidean distance between two points.\n",
        "    \"\"\"\n",
        "    dx = p1[:,0] - p2.reshape((-1, p1.shape[1]))[:,0]\n",
        "    dy = p1[:,1] - p2.reshape((-1, p1.shape[1]))[:,1]\n",
        "    return np.sqrt(dx * dx + dy * dy)\n",
        "\n",
        "def best_point(pt, p1, p2):\n",
        "    \"\"\"\n",
        "    Compare a user-defined point with two reference points, and select whichever reference point is the nearest.\n",
        "    \"\"\"\n",
        "    if p1 is None:\n",
        "        return p2.reshape((-1, pt.shape[1]))\n",
        "\n",
        "    if p2 is None:\n",
        "        return p1.reshape((-1, pt.shape[1]))\n",
        "    else:\n",
        "        d1 = Euclidean_distance(pt, p1)\n",
        "        d2 = Euclidean_distance(pt, p2)\n",
        "        if d1 < d2:\n",
        "            return p1.reshape((-1, pt.shape[1]))\n",
        "        else:\n",
        "            return p2.reshape((-1, pt.shape[1]))\n",
        "\n",
        "\n",
        "def kdtree(data, depth = 0):\n",
        "    \"\"\"\n",
        "    Construct a kDTree.\n",
        "    \"\"\"\n",
        "    n_samp = data.shape[0]\n",
        "    if n_samp != 0:\n",
        "        axis = depth % data.shape[1]\n",
        "        sort_data = data[data[ : , axis].argsort()]\n",
        "\n",
        "        return {'point': sort_data[n_samp // 2,:],\n",
        "             'left': kdtree(sort_data[ : n_samp // 2, : ], depth+1),\n",
        "            'right': kdtree(sort_data[n_samp // 2 + 1:, : ], depth+1)}\n",
        "\n",
        "\n",
        "def search_nearest_neighbor(kd, pt, depth = 0):\n",
        "\n",
        "    if kd is not None:\n",
        "        axis = depth % pt.shape[1]\n",
        "\n",
        "        next_branch     = None\n",
        "        opposite_branch = None\n",
        "\n",
        "        if pt[:,axis] < kd['point'][axis]:\n",
        "            next_branch     = kd['left']\n",
        "            opposite_branch = kd['right']\n",
        "        else:\n",
        "            next_branch     = kd['right']\n",
        "            opposite_branch = kd['left']\n",
        "\n",
        "        best = best_point(pt, search_nearest_neighbor(next_branch, pt, depth + 1), kd['point'])\n",
        "        if Euclidean_distance(pt, best) > (pt[:,axis] - kd['point'][axis]):\n",
        "            print('entered')\n",
        "            best = best_point(pt, search_nearest_neighbor(opposite_branch, pt, depth + 1), best)\n",
        "            print(best)\n",
        "        return best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504188d9",
      "metadata": {
        "id": "504188d9",
        "outputId": "887ab099-2feb-48b6-b208-e8f4fb4e04e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.19270097 0.9707951 ]]\n",
            "entered\n",
            "[[0.18269336 0.85351288]]\n",
            "entered\n",
            "[[0.18269336 0.85351288]]\n",
            "[[0.18269336 0.85351288]]\n",
            "[[0.12496709 0.39759237]]\n",
            "entered\n",
            "[[0.29397577 0.1662737 ]]\n",
            "entered\n",
            "[[0.23480835 0.02635385]]\n",
            "entered\n",
            "[[0.23480835 0.02635385]]\n",
            "[[0.29397577 0.1662737 ]]\n",
            "[[0.12496709 0.39759237]]\n",
            "[[0.39542284 0.51066973]]\n",
            "entered\n",
            "[[0.72901374 0.5612396 ]]\n",
            "entered\n",
            "[[0.72901374 0.5612396 ]]\n",
            "[[0.72901374 0.5612396 ]]\n",
            "entered\n",
            "[[0.72901374 0.5612396 ]]\n",
            "[[0.72901374 0.5612396 ]]\n",
            "entered\n",
            "[[0.95537189 0.98421347]]\n",
            "entered\n",
            "[[0.95537189 0.98421347]]\n",
            "[[0.72901374 0.5612396 ]]\n",
            "[[0.39542284 0.51066973]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##\n",
        "# Create a small dataset to test the recently created kD algorithm:\n",
        "#\n",
        "seed = 28\n",
        "np.random.seed(seed)\n",
        "\n",
        "X = np.random.rand(10, 2)\n",
        "Y = np.random.rand(1, 2)\n",
        "\n",
        "##\n",
        "# Test the recently created kD algorithm\n",
        "#\n",
        "tree = kdtree(X)\n",
        "nn = search_nearest_neighbor(tree, Y)\n",
        "\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X[ : , 0], y = X[ : , 1], label = 'Training data')\n",
        "axs.scatter(nn[ : , 0], nn[ : , 1], label = 'NN')\n",
        "axs.scatter(Y[ : , 0], Y[ : , 1], label = 'Test data' )\n",
        "axs.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c984d5",
      "metadata": {
        "id": "92c984d5"
      },
      "source": [
        "### Problem 2\n",
        "Note: in this problem, I tried to get the same result as in the given example (in Figure 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f2deef",
      "metadata": {
        "id": "81f2deef"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# Construct matrix X:\n",
        "#\n",
        "mean_X1 = (2,2)\n",
        "cov_X1 = np.array([[1, 0], [0, 1]])\n",
        "X1 = np.random.multivariate_normal(mean_X1, cov_X1, size = 5000)\n",
        "\n",
        "mean_X2 = (5,5)\n",
        "cov_X2 = np.array([[1, 0], [0, 1]])\n",
        "X2 = np.random.multivariate_normal(mean_X2, cov_X2, size = 5000)\n",
        "\n",
        "X = np.concatenate((X1,X2), axis = 0)\n",
        "\n",
        "##\n",
        "# Construct matrix Y:\n",
        "#\n",
        "Y1 = np.zeros(X1.shape[0])\n",
        "Y2 = np.ones(X2.shape[0])\n",
        "\n",
        "Y = np.concatenate((Y1, Y2), axis = 0)\n",
        "\n",
        "##\n",
        "# Sanity check:\n",
        "#\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X1[ : , 0], y = X1[ : , 1], label = 'X1')\n",
        "axs.scatter(x = X2[ : , 0], y = X2[ : , 1], label = 'X2')\n",
        "axs.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663be94a",
      "metadata": {
        "id": "663be94a"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# Partition X and Y into training and test sets:\n",
        "#\n",
        "cutoff = 0.8\n",
        "mask = np.random.rand(X.shape[0]) < cutoff\n",
        "X_train = X[mask]\n",
        "X_test = X[np.logical_not(mask)]\n",
        "\n",
        "Y_train = Y[mask]\n",
        "Y_test = Y[np.logical_not(mask)]\n",
        "\n",
        "##\n",
        "# Sanity check\n",
        "#\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X_train[ : , 0], y = X_train[ : , 1], label = 'X_train')\n",
        "axs.scatter(x = X_test[ : , 0], y = X_test[ : , 1], label = 'X_test')\n",
        "axs.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b72d1057",
      "metadata": {
        "id": "b72d1057"
      },
      "source": [
        "### Problem 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7456c6d3",
      "metadata": {
        "id": "7456c6d3"
      },
      "outputs": [],
      "source": [
        "def LLS(X,Y):\n",
        "    \"\"\"\n",
        "    Construct the maximum-likelihood linear least squares function (Y = beta * X).\n",
        "    \"\"\"\n",
        "    X_T = np.transpose(X)\n",
        "    beta = np.dot(np.dot(np.linalg.inv(np.dot(X_T, X)), X_T), Y)\n",
        "    return beta\n",
        "\n",
        "def LLS_classify(X, beta, threshold: float):\n",
        "    \"\"\"\n",
        "    Classify the elements of a set using the linear least square function with a threshold.\n",
        "    \"\"\"\n",
        "    Yhat = np.dot(X, beta)\n",
        "    Yhat = np.where(Yhat < threshold, 0, 1)\n",
        "    return Yhat\n",
        "\n",
        "def get_elements_from_training_set(X_train, Y_train, class_Y: int):\n",
        "    \"\"\"\n",
        "    Get training set elements from a user-defined class.\n",
        "    \"\"\"\n",
        "    return X_train[Y_train == class_Y, :]\n",
        "\n",
        "def get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, class_Y: int):\n",
        "    \"\"\"\n",
        "    Get correctly classified test set elements from a user-defined class.\n",
        "    \"\"\"\n",
        "    class_corrected = []\n",
        "    for i in range(0, Y_test.shape[0]):\n",
        "        if Y_test[i] == class_Y:\n",
        "            if Yhat_test[i] == Y_test[i]:\n",
        "                class_corrected.append(i)\n",
        "\n",
        "    return X_test[class_corrected, :]\n",
        "\n",
        "def get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, class_Y: int):\n",
        "    \"\"\"\n",
        "    Get incorrectly classified test set elements from a user-defined class.\n",
        "    \"\"\"\n",
        "    class_incorrected = []\n",
        "    for i in range(0, Y_test.shape[0]):\n",
        "        if Y_test[i] == class_Y:\n",
        "            if Yhat_test[i] != Y_test[i]:\n",
        "                class_incorrected.append(i)\n",
        "\n",
        "    return X_test[class_incorrected, :]\n",
        "\n",
        "def compute_classifier_accuracy(X, Y, Yhat):\n",
        "    \"\"\"\n",
        "    Compute the accuracy of a binary classifier.\n",
        "    \"\"\"\n",
        "    class_1_corrected = get_corrected_elements_from_test_set(X, Y, Yhat, 1)\n",
        "    class_0_corrected = get_corrected_elements_from_test_set(X, Y, Yhat, 0)\n",
        "    accuracy = (class_1_corrected.shape[0] + class_0_corrected.shape[0]) / X.shape[0]\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828821b8",
      "metadata": {
        "id": "828821b8"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# Construct a linear least square function:\n",
        "#\n",
        "beta = LLS(X_train, Y_train)\n",
        "\n",
        "##\n",
        "# Classify elements in the test set:\n",
        "#\n",
        "Yhat_test = LLS_classify(X_test, beta, 0.5)\n",
        "\n",
        "##\n",
        "# Get elements from training set:\n",
        "#\n",
        "X_train_class_1 = get_elements_from_training_set(X_train, Y_train, 1)\n",
        "X_train_class_0 = get_elements_from_training_set(X_train, Y_train, 0)\n",
        "\n",
        "##\n",
        "# Get elements from test set:\n",
        "#\n",
        "X_test_class_1_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "X_test_class_1_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "\n",
        "##\n",
        "# Compute the accuracy:\n",
        "#\n",
        "accuracy = compute_classifier_accuracy(X_test, Y_test, Yhat_test)\n",
        "print(accuracy)\n",
        "\n",
        "##\n",
        "# Plot elements of sets:\n",
        "#\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X_train_class_1[ : , 0], y = X_train_class_1[ : , 1], label = 'X_train_class_1')\n",
        "axs.scatter(x = X_train_class_0[ : , 0], y = X_train_class_0[ : , 1], label = 'X_train_class_0')\n",
        "axs.scatter(x = X_test_class_1_corrected[ : , 0], y = X_test_class_1_corrected[ : , 1],\n",
        "            label = 'X_test_class_1_corrected')\n",
        "axs.scatter(x = X_test_class_0_corrected[ : , 0], y = X_test_class_0_corrected[ : , 1],\n",
        "            label = 'X_test_class_0_corrected')\n",
        "axs.scatter(x = X_test_class_1_incorrected[ : , 0], y = X_test_class_1_incorrected[ : , 1],\n",
        "            label = 'X_test_class_1_incorrected')\n",
        "axs.scatter(x = X_test_class_0_incorrected[ : , 0], y = X_test_class_0_incorrected[ : , 1],\n",
        "            label = 'X_test_class_0_incorrected')\n",
        "axs.legend(loc = 'lower right')\n",
        "plt.show()\n",
        "\n",
        "##\n",
        "# Sanity check:\n",
        "#\n",
        "print(beta.shape)\n",
        "print(Yhat_test.shape)\n",
        "print(X_train_class_1.shape)\n",
        "print(X_train_class_0.shape)\n",
        "print(X_test_class_1_corrected.shape)\n",
        "print(X_test_class_0_corrected.shape)\n",
        "print(X_test_class_1_incorrected.shape)\n",
        "print(X_test_class_0_incorrected.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061441a6",
      "metadata": {
        "id": "061441a6"
      },
      "source": [
        "### Problem 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946a52d9",
      "metadata": {
        "id": "946a52d9"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# Construct a kD tree from the training set:\n",
        "#\n",
        "tree = cKDTree(X_train)\n",
        "\n",
        "##\n",
        "# Use the tree to classify the test set:\n",
        "#\n",
        "_ , indices = tree.query(X_test)\n",
        "Yhat_test = Y_train[indices]\n",
        "\n",
        "##\n",
        "# Get elements from test set:\n",
        "#\n",
        "X_test_class_1_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "X_test_class_1_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "\n",
        "##\n",
        "# Compute the accuracy:\n",
        "#\n",
        "accuracy = compute_classifier_accuracy(X_test, Y_test, Yhat_test)\n",
        "print(accuracy)\n",
        "\n",
        "##\n",
        "# Plot elements of sets:\n",
        "#\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X_train_class_1[ : , 0], y = X_train_class_1[ : , 1], label = 'X_train_class_1')\n",
        "axs.scatter(x = X_train_class_0[ : , 0], y = X_train_class_0[ : , 1], label = 'X_train_class_0')\n",
        "axs.scatter(x = X_test_class_1_corrected[ : , 0], y = X_test_class_1_corrected[ : , 1],\n",
        "            label = 'X_test_class_1_corrected')\n",
        "axs.scatter(x = X_test_class_0_corrected[ : , 0], y = X_test_class_0_corrected[ : , 1],\n",
        "            label = 'X_test_class_0_corrected')\n",
        "axs.scatter(x = X_test_class_1_incorrected[ : , 0], y = X_test_class_1_incorrected[ : , 1],\n",
        "            label = 'X_test_class_1_incorrected')\n",
        "axs.scatter(x = X_test_class_0_incorrected[ : , 0], y = X_test_class_0_incorrected[ : , 1],\n",
        "            label = 'X_test_class_0_incorrected')\n",
        "axs.legend(loc = 'lower right')\n",
        "plt.show()\n",
        "\n",
        "##\n",
        "# Sanity check:\n",
        "#\n",
        "print(beta.shape)\n",
        "print(Yhat_test.shape)\n",
        "print(X_train_class_1.shape)\n",
        "print(X_train_class_0.shape)\n",
        "print(X_test_class_1_corrected.shape)\n",
        "print(X_test_class_0_corrected.shape)\n",
        "print(X_test_class_1_incorrected.shape)\n",
        "print(X_test_class_0_incorrected.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4cc0a3b",
      "metadata": {
        "id": "d4cc0a3b"
      },
      "source": [
        "### Problem 5\n",
        "Note: in this problem, I created 10 overlapping Gaussian distributions, each with a randomized mean and a randomized variance from 0 to 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7c1038",
      "metadata": {
        "id": "6f7c1038"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# Create 10 different overlapping Gaussian distributions:\n",
        "#\n",
        "seed = 28\n",
        "np.random.seed(28)\n",
        "\n",
        "means = [[x1, x2] for x1, x2 in zip(np.random.rand(10) * 10, np.random.rand(10) * 10)]\n",
        "covs = [[[i, 0], [0, i]] for i in (np.random.rand(10) * 10)]\n",
        "X = [np.random.multivariate_normal(mean, cov, 1000) for mean, cov in zip(means, covs)]\n",
        "\n",
        "##\n",
        "# Create X:\n",
        "#\n",
        "X = np.vstack(X)\n",
        "\n",
        "##\n",
        "# Create Y:\n",
        "#\n",
        "Y = np.zeros(10000)\n",
        "Y[5000:] = 1\n",
        "\n",
        "##\n",
        "# Partition X and Y into training and test sets:\n",
        "#\n",
        "cutoff = 0.8\n",
        "mask = np.random.rand(X.shape[0]) < cutoff\n",
        "X_train = X[mask]\n",
        "X_test = X[np.logical_not(mask)]\n",
        "\n",
        "Y_train = Y[mask]\n",
        "Y_test = Y[np.logical_not(mask)]\n",
        "\n",
        "##\n",
        "# Sanity check:\n",
        "#\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X_train[ : , 0], y = X_train[ : , 1], label = 'X_train')\n",
        "axs.scatter(x = X_test[ : , 0], y = X_test[ : , 1], label = 'X_test')\n",
        "axs.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c61b6d",
      "metadata": {
        "id": "69c61b6d"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# Perform linear classification:\n",
        "#\n",
        "beta = LLS(X_train, Y_train)\n",
        "Yhat_test = LLS_classify(X_test, beta, 0.5)\n",
        "\n",
        "##\n",
        "# Get elements from training set:\n",
        "#\n",
        "X_train_class_1 = get_elements_from_training_set(X_train, Y_train, 1)\n",
        "X_train_class_0 = get_elements_from_training_set(X_train, Y_train, 0)\n",
        "\n",
        "##\n",
        "# Get elements from test set:\n",
        "#\n",
        "X_test_class_1_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "X_test_class_1_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "\n",
        "##\n",
        "# Compute the accuracy:\n",
        "#\n",
        "accuracy = compute_classifier_accuracy(X_test, Y_test, Yhat_test)\n",
        "print(accuracy)\n",
        "\n",
        "##\n",
        "# Plot elements of sets:\n",
        "#\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X_train_class_1[ : , 0], y = X_train_class_1[ : , 1], label = 'X_train_class_1')\n",
        "axs.scatter(x = X_train_class_0[ : , 0], y = X_train_class_0[ : , 1], label = 'X_train_class_0')\n",
        "axs.scatter(x = X_test_class_1_corrected[ : , 0], y = X_test_class_1_corrected[ : , 1],\n",
        "            label = 'X_test_class_1_corrected')\n",
        "axs.scatter(x = X_test_class_0_corrected[ : , 0], y = X_test_class_0_corrected[ : , 1],\n",
        "            label = 'X_test_class_0_corrected')\n",
        "axs.scatter(x = X_test_class_1_incorrected[ : , 0], y = X_test_class_1_incorrected[ : , 1],\n",
        "            label = 'X_test_class_1_incorrected')\n",
        "axs.scatter(x = X_test_class_0_incorrected[ : , 0], y = X_test_class_0_incorrected[ : , 1],\n",
        "            label = 'X_test_class_0_incorrected')\n",
        "axs.legend(loc = 'lower right')\n",
        "plt.show()\n",
        "\n",
        "##\n",
        "# Sanity check:\n",
        "#\n",
        "print(beta.shape)\n",
        "print(Yhat_test.shape)\n",
        "print(X_train_class_1.shape)\n",
        "print(X_train_class_0.shape)\n",
        "print(X_test_class_1_corrected.shape)\n",
        "print(X_test_class_0_corrected.shape)\n",
        "print(X_test_class_1_incorrected.shape)\n",
        "print(X_test_class_0_incorrected.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d004d7",
      "metadata": {
        "id": "d9d004d7"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# Perform kDTree's classification:\n",
        "#\n",
        "tree = cKDTree(X_train)\n",
        "\n",
        "##\n",
        "# Use the tree to classify the test set:\n",
        "#\n",
        "_ , indices = tree.query(X_test)\n",
        "Yhat_test = Y_train[indices]\n",
        "\n",
        "##\n",
        "# Get elements from test set:\n",
        "#\n",
        "X_test_class_1_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_corrected = get_corrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "X_test_class_1_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 1)\n",
        "X_test_class_0_incorrected = get_incorrected_elements_from_test_set(X_test, Y_test, Yhat_test, 0)\n",
        "\n",
        "##\n",
        "# Compute the accuracy:\n",
        "#\n",
        "accuracy = compute_classifier_accuracy(X_test, Y_test, Yhat_test)\n",
        "print(accuracy)\n",
        "\n",
        "##\n",
        "# Plot elements of sets:\n",
        "#\n",
        "fig, axs = plt.subplots()\n",
        "axs.scatter(x = X_train_class_1[ : , 0], y = X_train_class_1[ : , 1], label = 'X_train_class_1')\n",
        "axs.scatter(x = X_train_class_0[ : , 0], y = X_train_class_0[ : , 1], label = 'X_train_class_0')\n",
        "axs.scatter(x = X_test_class_1_corrected[ : , 0], y = X_test_class_1_corrected[ : , 1],\n",
        "            label = 'X_test_class_1_corrected')\n",
        "axs.scatter(x = X_test_class_0_corrected[ : , 0], y = X_test_class_0_corrected[ : , 1],\n",
        "            label = 'X_test_class_0_corrected')\n",
        "axs.scatter(x = X_test_class_1_incorrected[ : , 0], y = X_test_class_1_incorrected[ : , 1],\n",
        "            label = 'X_test_class_1_incorrected')\n",
        "axs.scatter(x = X_test_class_0_incorrected[ : , 0], y = X_test_class_0_incorrected[ : , 1],\n",
        "            label = 'X_test_class_0_incorrected')\n",
        "axs.legend(loc = 'lower right')\n",
        "plt.show()\n",
        "\n",
        "##\n",
        "# Sanity check:\n",
        "#\n",
        "print(beta.shape)\n",
        "print(Yhat_test.shape)\n",
        "print(X_train_class_1.shape)\n",
        "print(X_train_class_0.shape)\n",
        "print(X_test_class_1_corrected.shape)\n",
        "print(X_test_class_0_corrected.shape)\n",
        "print(X_test_class_1_incorrected.shape)\n",
        "print(X_test_class_0_incorrected.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f973ba5b",
      "metadata": {
        "id": "f973ba5b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}