{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4oKbqMWMpMN"
   },
   "source": [
    "# CS[45]783 HW2: Single-Layered Neural Networks\n",
    "\n",
    "In this homework assignment, you will build a simple linear model using differential modules.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CLyvlysHCK9"
   },
   "source": [
    "## Starting Our Modular API\n",
    "\n",
    "### **The goal of this assignment is as follows:** \n",
    "- Organize our understanding of deep learning into a modular framework. \n",
    "- Get familiarized with a simple modular API which reflects (but is a simplification of) some of PyTorch's systems. \n",
    "- Implement some nice modular components and be able to construct a functional single-file neural network from it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTfm_9fmHkhE"
   },
   "source": [
    "Recall that per the chain rule, if there exists a set of differentiable functions $c(b)$ and $b(a)$, then \n",
    "\n",
    "$$\\frac{\\partial a}{\\partial c} = \\frac{\\partial a}{\\partial b} \\frac{\\partial b}{\\partial c}$$\n",
    "\n",
    "Going back to our regression model, let's assume that we have a layered process: \n",
    "\n",
    "$$x \\to h_\\theta(x) \\to \\mathcal{L}(h_\\theta)$$\n",
    "\n",
    "This implies that we can compute the partial of the trainable parameters $\\theta$ through a loss evaluation $\\mathcal{L}$ and a dense layer $h_\\theta(x)$ by the following relationship:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\frac{\\partial \\mathcal{h_\\theta}}{\\partial \\theta}\\frac{\\partial \\mathcal{L}}{\\partial h_\\theta}$$\n",
    "\n",
    "With a similar logic, you can also make the assertion that you can also get the partial with respect to the input $x$:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial x} = \\frac{\\partial h_\\theta}{\\partial x}\\frac{\\partial \\mathcal{L}}{\\partial h_\\theta}$$\n",
    "\n",
    "So... by the same token, is there anything stopping us from going further? Let's say that we decided to have another hypothesis function such that $x = h'_{\\theta'}(x')$ for some other hypothesis function and inputs? The new structure would then be: \n",
    "\n",
    "$$x' \\to \\big[ x = h'_{\\theta'}(x') \\big] \\to h_\\theta(x) \\to \\mathcal{L}(h_\\theta)$$\n",
    "\n",
    "Without the chain rule, coding in the facilities to optimize $\\theta'$ might have been tricky, but with the chain rule we know that:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta'} \n",
    "= \\frac{\\partial x}{\\partial \\theta'}\\frac{\\partial h}{\\partial x}\\frac{\\partial \\mathcal{L}}{\\partial h} \n",
    "= \\frac{\\partial x}{\\partial \\theta'}\\frac{\\partial \\mathcal{L}}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUJfaOFpIJbD"
   },
   "source": [
    "Notice how this process is both predictable and scales very well! Say that we wanted to add some activation functions to restrict the range of the hypothesis functions. This trivially inserts into the chain and everything still works and will look something like this: \n",
    "\n",
    "$$ \\frac{\\partial \\mathcal{L}}{\\partial x} = \\frac{\\partial h}{\\partial x}\\frac{\\partial a}{\\partial h}\\frac{\\partial \\mathcal{L}}{\\partial a} \n",
    "\\ \\text{ and } \\ \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\frac{\\partial h}{\\partial \\theta}\\frac{\\partial a}{\\partial h}\\frac{\\partial \\mathcal{L}}{\\partial a} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVyTXT5TIOsz"
   },
   "source": [
    "And with that, we start to approach the reason why this is such a powerful formulation: The cumulative nature of the process. Specifically, consider the process that needs to happen in order to compute this for the extended 2-layer example: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial a}{\\partial h}\\frac{\\partial \\mathcal{L}}{\\partial a} \n",
    "= \\frac{\\partial \\mathcal{L}}{\\partial h} \n",
    "&\\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial x} \n",
    "&\\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial a'}\n",
    "&\\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial h'} \n",
    "&\\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial x'} \n",
    "\\\\\n",
    "&\\searrow \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial \\theta} \n",
    "&&&\\searrow \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial \\theta'} \n",
    "% \\\\\n",
    "% &\\searrow \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial \\theta} \n",
    "% \\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial a'} \n",
    "% \\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial h'} \n",
    "% &\n",
    "% \\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial \\theta'} \n",
    "% \\\\ \n",
    "% &&\n",
    "% \\to \\cdots = \\frac{\\partial \\mathcal{L}}{\\partial x'} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "... and this is the process known as **back-propagation** *(and a special case of **auto-differentiation**)*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdK16iXOVgta"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhgMs3u_S1OU"
   },
   "source": [
    "## Loading In Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV7vjVbTf9Xg"
   },
   "source": [
    "The first thing we have to do is load in our data to use our model with. We'll be working with the [diabetes dataset from the sklearn package](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset). We've already provided the code to load in the input data and the ground truth labels (stored as `X` and `Y` respectively below).\n",
    "\n",
    "**[TODO]:** Split the samples into training and testing sets. We'll train with the train set and reserve the testing set to evaluate the model's performance on samples it hasn't seen.\n",
    "\n",
    "The diabetes dataset has 442 samples. Each sample's input data has 10 data points for some key metrics, like age and cholesterol levels. The \"label\" is a number representing disease progression one year after baseline. Thus, `X` has shape `(442, 10)`, while `Y` has shape `(442,)`.\n",
    "\n",
    "**[TODO]:** Reshape the `Y` subsets to have shape `(num_samples, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gytrDuxV5gFO",
    "outputId": "25ac15b0-866c-43d8-cff9-ee36934b4551"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X, Y = diabetes.data, diabetes.target\n",
    "\n",
    "## TODO: Split the data into a 80%-20% training-testing split\n",
    "## TODO: Reshape the Y subsets to have shape (num_samples, 1)\n",
    "X0, X1, Y0, Y1 = None, None, None, None\n",
    "\n",
    "print(f\"\"\"\n",
    "> Input shape: {X0.shape} for training, {X1.shape} for testing\n",
    "> Label shape: {Y0.shape} for training, {Y1.shape} for testing\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIYU_639VgHq"
   },
   "source": [
    "## **Exploring a possible modular implementation: PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHs57_36jfDL"
   },
   "source": [
    "Next, we'll want to build up a Regression model interface, from which we can implement specific regression model classes, like the LinearRegression class we'll work with later. \n",
    "\n",
    "We subclass the `nn.Module class`, which represents any module (like a layer or model) of a deep learning system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DG6vkwv5chPg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Regression(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize all the inherent \"things\" inside of a model!\n",
    "    This includes things like the layers, activation/loss functions, and optimzer. \n",
    "    \"\"\"\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")        \n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dims, output_dims).to(self.device)   \n",
    "        self.activation = None  ## To be specified in subclasses \n",
    "        self.loss = None        ## To be specified in subclasses \n",
    "        self.set_learning_rate()\n",
    "\n",
    "    \"\"\"\n",
    "    Sets up the optmizer\n",
    "    \"\"\"\n",
    "    def set_learning_rate(self, learning_rate=0.001):\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate) ## Simple stochastic gradient descent (SGD) optimizer\n",
    "\n",
    "    \"\"\"\n",
    "    Forward pass of the model\n",
    "    Given an input x, how does the model process the input to get its output?\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTzEFlA0TFZB"
   },
   "source": [
    "## Adding a PyTorch Training/Evaluation Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBSK640PoDWX"
   },
   "source": [
    "Now that we have the basis for a Regression model, we need to describe how to train (`fit`) and evaluate (`evaluate`) our model, given data. \n",
    "Every epoch, we want to fit our model to the training data, and then evaluate our model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUetVEGtS9k9"
   },
   "outputs": [],
   "source": [
    "class TrainTest:\n",
    "\n",
    "    no_grad = torch.no_grad\n",
    "\n",
    "    def fit(self, data):\n",
    "        ## Training loop\n",
    "        self.train()        ## Set model into training mode\n",
    "        ## Iterate over the data batches\n",
    "        for batch, (inputs, target) in enumerate(data):\n",
    "            ## In real pytorch, you'd need to set the device\n",
    "            inputs = inputs.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            ## Erase the gradient history\n",
    "            self.optimizer.zero_grad()\n",
    "            ## Do a forward pass on the model\n",
    "            output = self(inputs)\n",
    "            ## Compute the loss\n",
    "            loss = self.loss(output, target)\n",
    "            ## Run backwards pass from the loss through the previous layers\n",
    "            ## This will accumulate gradients for the parameters that need to be optimized\n",
    "            loss.backward()\n",
    "            ## Perform a single optimization step\n",
    "            self.optimizer.step()\n",
    "        return {'loss' : loss}\n",
    "\n",
    "    def evaluate(self, data):\n",
    "        ## Set model into \"evaluate\" mode so that the parameters don't get updated\n",
    "        self.eval()\n",
    "        total_loss = 0\n",
    "        ## Cut off the tensor training scope to make sure weights aren't updated\n",
    "        ## For now, it's torch.no_grad; later, you'll use Tensor.no_grad\n",
    "        with TrainTest.no_grad():\n",
    "            for inputs, target in data:\n",
    "                ## In real pytorch, you'd need to set the device\n",
    "                inputs = inputs.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                output = self(inputs)\n",
    "                total_loss += self.loss(output, target).item()  # sum up batch loss\n",
    "\n",
    "        total_loss /= len(data)\n",
    "        return {'test_loss' : total_loss}\n",
    "        \n",
    "    def train_test(self, train_data, test_data, epochs=1):\n",
    "        ## Does both training and validation on a per-epoch basis\n",
    "        all_stats = []\n",
    "        for epoch in range(epochs):\n",
    "            train_stats = self.fit(train_data)\n",
    "            test_stats = self.evaluate(test_data)\n",
    "            all_stats += [{**train_stats, **test_stats}]\n",
    "            print(f'[Epoch {epoch+1}/{epochs}]', all_stats[-1])\n",
    "        return all_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDNhzYnUTNMa"
   },
   "source": [
    "## Making Linear Regression with Train/Test Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njv7q2UTTgQE"
   },
   "source": [
    "Next, we implement the `LinearRegression` class, which subclasses both `Regression` and `TrainTest` to inherit useful methods. \n",
    "\n",
    "Consider a dense layer represented by $Y = XA + B$ where: \n",
    "- $X$ has shape `(n,input_dims)`\n",
    "- $A$ has shape `(input_dims,output_dims)`\n",
    "- $B$ has shape `(n,)`\n",
    "- $Y$ has shape `(n, output_dims)`. \n",
    "\n",
    "Let each row of $X, B, Y$ (or the 0$^\\text{th}$ dimension) represent a different sample. Disregarding bias, note how any given row in $Y$ is a set of linear combinations of the same row in $X$. In other words, a Dense Layer is high-dimensional Linear Regression. \n",
    "\n",
    "Once you've built up your model, try training and testing it in the code block below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYU8NKSdTc4W"
   },
   "outputs": [],
   "source": [
    "class LinearRegression(Regression, TrainTest):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__(input_dims, output_dims)\n",
    "        self.activation = nn.Identity()\n",
    "        self.loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBUaTs3N_hmn",
    "outputId": "3fce3c13-46cf-4ae1-835a-53e3ed3de277"
   },
   "outputs": [],
   "source": [
    "torch_model = LinearRegression(X0.shape[-1], 1)\n",
    "torch_model.set_learning_rate(0.3)\n",
    "torch_model.train_test(\n",
    "    [[torch.Tensor(X0), torch.Tensor(Y0)]], \n",
    "    [[torch.Tensor(X1), torch.Tensor(Y1)]],\n",
    "    epochs=200\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H63TERfyvZtS"
   },
   "source": [
    "## Shapes That Might Be Useful..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtwbP5tRbJky"
   },
   "source": [
    "Throughout the duration of this course, you might find it really helpful to check the shapes of each of your different tensors and outputs just to verify that everything is working as intended. Check the block below to see an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBkTktWcD9dz",
    "outputId": "b3ec3eb7-fbc0-4337-8ad3-1e20e1d3aa62"
   },
   "outputs": [],
   "source": [
    "y_true = torch.Tensor(Y0)\n",
    "y_pred = torch_model(torch.Tensor(X0))\n",
    "loss = torch_model.loss(y_true, y_pred)\n",
    "\n",
    "print(f\"\"\"\n",
    "> Prediction Shape: {y_pred.shape}\n",
    "> Weights    Shape: {list(torch_model.parameters())[0].shape}\n",
    "> Bias       Shape: {list(torch_model.parameters())[1].shape}\n",
    "> Loss       Shape: {loss.shape}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cu1pLK46fFqX"
   },
   "source": [
    "Next, let's start building up all the different parts of the basic PyTorch tools that we used in order to see what's under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZfozqWdLB2V"
   },
   "source": [
    "## PyTorch Complexity Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVv6iQios7-D"
   },
   "source": [
    "### Tensors\n",
    "- Tensors are responsible for maintaining their own gradients\n",
    "- Tensors hold on to `backward` functions to which they can pass a gradient into. These backwards functions are provided by the layers associated with those tensors. \n",
    "    - If a tensor is a terminal node, it will pass in an upstream gradient of `None`.\n",
    "    - If a tensor is a non-terminal node, it will pass the accumulated upstream gradient. \n",
    "    - `backward` functions as a linked list algorithm and crawls back the chain, computing the gradient for every tensor that it hits (as long as they require a gradient).\n",
    "- Since the tensors hold their own gradients, the optimizer can merely take the tensors' values, take their gradients, and then just optimize them.\n",
    "- However, because tensors are always keeping track of their gradients when `requires_grad` is set to `True`, we also want to add a way to stop tracking gradients.\n",
    "    - For instance, while evaluating the performance of our model, we want to make sure that the model doesn't learn anything from this evaluation phase.\n",
    "    - We can use the `no_grad` subclass to automatically handle the flipping of this `requires_grad` value. \n",
    "        - Every time we enter a `with Tensor.no_grad():` block, the code within `no_grad`'s `__enter__()` method will execute. \n",
    "        - Once we exit the same `with Tensor.no_grad():` block, `no_grad`'s `__exit()__` method will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZbMLm30y3tD"
   },
   "outputs": [],
   "source": [
    "class Tensor(np.ndarray):\n",
    "\n",
    "    '''\n",
    "    Subclassing numpy arrays is a bit weird:\n",
    "    https://numpy.org/doc/stable/user/basics.subclassing.html\n",
    "\n",
    "    Just assume that the attributes referred to in __new__/__array_finalize__ \n",
    "    will be accessible in a Tensor when a new Tensor object is created.  \n",
    "    '''\n",
    "\n",
    "    requires_grad = True  ## Class variable; accessible by Tensor.requires_grad\n",
    "\n",
    "    def __new__(cls, input_array):\n",
    "        obj = np.asarray(input_array).view(cls)\n",
    "        obj.backward = lambda x: None   ## Backward starts as None, gets assigned later\n",
    "        obj.grad = None                 ## Gradient starts as None, gets computed later\n",
    "        obj.requires_grad = True        ## By default, we'll want to compute gradient for new tensors\n",
    "        obj.to = lambda x: obj          ## We don't handle special device support (i.e. cpu vs gpu/cuda)\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        if obj is None: return\n",
    "        self.backward       = getattr(obj, 'backward',      lambda x: None)\n",
    "        self.to             = getattr(obj, 'to',            lambda x: obj)\n",
    "        self.grad           = getattr(obj, 'grad',          None)\n",
    "        self.requires_grad  = getattr(obj, 'requires_grad', None)\n",
    "\n",
    "    class no_grad():\n",
    "\n",
    "        '''\n",
    "        Synergizes with Tensor: By entering the tensor with no_grad scope, \n",
    "        the Tensor.requires_grad singleton will swap to False. \n",
    "        '''\n",
    "        \n",
    "        def __enter__(self):\n",
    "            # When tape scope is entered, stop asking tensors to record gradients\n",
    "            Tensor.requires_grad = False\n",
    "            return self\n",
    "\n",
    "        def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "            # When tape scope is exited, let Diffable start recording to self.operation\n",
    "            Tensor.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovL7L6STvXCU"
   },
   "source": [
    "### Diffable\n",
    "\n",
    "Let's specify a \"Diffable\" object which will represent a module that can be differentiated. This class will make the following assumptions: \n",
    "- Gradients will need to flow through the input pathways in order to compute earlier gradients. \n",
    "    - Therefore, inputs will need an appropriate \"backward\"\n",
    "- Parameters will need to recieve gradients.\n",
    "- More specifically, if a `Diffable` object performs an operation on some input, then we know that the gradient from the output of the Diffable w.r.t. the inputs is the gradient of the `Diffable`'s operations w.r.t. its inputs.\n",
    "  - Thus, a `Diffable`'s `input_gradients()` function should return a tuple with each of the partial derivatives of the operations performed in the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9v68mc_U1ymJ"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod  # # For abstract method support\n",
    "\n",
    "class Diffable(ABC):\n",
    "    \"\"\"\n",
    "        We use these to represent differentiable layers which we can compute gradients for.\n",
    "    \"\"\"\n",
    "\n",
    "    def to(self, device):\n",
    "        return self         # Just there to ignore device setting calls\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \n",
    "        ## The call method keeps track of method inputs and outputs\n",
    "        self.argnames   = self.forward.__code__.co_varnames[1:]\n",
    "        named_args      = {self.argnames[i] : args[i] for i in range(len(args))}\n",
    "        self.input_dict = {**named_args, **kwargs}\n",
    "        self.inputs     = [self.input_dict[arg] for arg in self.argnames if arg in self.input_dict.keys()]\n",
    "        self.outputs    = self.forward(*args, **kwargs)\n",
    "\n",
    "        ## Make sure outputs are tensors and tie back to this layer\n",
    "        list_outs = isinstance(self.outputs, list) or isinstance(self.outputs, tuple)\n",
    "        if not list_outs:\n",
    "            self.outputs = [self.outputs]\n",
    "        self.outputs = [Tensor(out) for out in self.outputs]\n",
    "        for out in self.outputs: \n",
    "            out.backward = self.backward\n",
    "\n",
    "        # print(self.__class__.__name__.ljust(24), [v.shape for v in self.inputs], '->', [v.shape for v in self.outputs])\n",
    "            \n",
    "        ## And then finally, it returns the output, thereby wrapping the forward\n",
    "        return self.outputs if list_outs else self.outputs[0]\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Returns a list of parameters\"\"\"\n",
    "        return ()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        \"\"\"Pass inputs through function. Can store inputs and outputs as instance variables\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def input_gradients(self):\n",
    "        \"\"\"Returns local gradient of layer output w.r.t. input\"\"\"\n",
    "        pass\n",
    "\n",
    "    def weight_gradients(self):\n",
    "        \"\"\"Returns local gradient of layer output w.r.t. weights\"\"\"\n",
    "        return []\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self, grad=np.array([[1]])):\n",
    "        \"\"\"\n",
    "        Propagate upstream gradient backwards by composing with local gradient\n",
    "        \n",
    "        SCAFFOLD: \n",
    "\n",
    "        Differentiate with respect to layer parameters:\n",
    "            For every param-gradient pair\n",
    "            - If all Tensors or this tensor do not require gradients, then skip\n",
    "            - Otherwise, compose upstream and local gradient\n",
    "        \n",
    "        Differentiate with respect to layer input:\n",
    "            For every input-gradient pair\n",
    "            - If all Tensors or this tensor do not require gradients, then skip\n",
    "            - Otherwise, compose upstream and local gradient\n",
    "\n",
    "        Usefulseful print boilerplate...: \n",
    "            # print(f'Diffing w.r.t. \"{k}\": local = {g.shape} and upstream = {grad.shape}')\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2n50HNq3ZuCO"
   },
   "source": [
    "### Loss\n",
    "**[TODO]:** Implement the forward pass in `forward()`.\n",
    "- The forward pass should just give the mean squared error between `y_pred` and `y_true`.\n",
    "\n",
    "**[TODO]:** Implement the backward pass in `backward()`.\n",
    "- This should take advantage of the layer inputs as well as the gradients computed with respect to them.\n",
    "- Feel free to only work with the input gradients, since this loss layer does not have any parameters.\n",
    "\n",
    "**[TODO]:** Calculate and return `input_gradients()`:\n",
    "- You want to calculate the gradients which flow to the inputs: `y_pred` and `y_true`\n",
    "- Note that we don't want to \"train\" `y_true`, so you can just return 0 for the grads for `y_true`\n",
    "- Return the partial derivative of mean squared error w.r.t. `y_pred`, and 0.\n",
    "\n",
    "Note that we don't need to implement `weight_gradients()` here because MSELoss doesn't have weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GG1E4VaC9hs"
   },
   "outputs": [],
   "source": [
    "class MSELoss(Diffable):\n",
    "\n",
    "    \"\"\"\n",
    "        Calculates mean squared error loss and gradient w.r.t. inputs.\n",
    "        Subclasses Diffable.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"Mean squared error forward pass!\"\"\"\n",
    "        # TODO: Compute and return the MSE given predicted and actual labels\n",
    "\n",
    "    def input_gradients(self):\n",
    "        \"\"\"Mean squared error backpropagation!\"\"\"\n",
    "        # TODO: Compute and return the gradients\n",
    "\n",
    "    def backward(self, grad=np.array([[1]])):\n",
    "        \"\"\"Mean squared error backpropagation!\"\"\"        \n",
    "        ## TODO: Differentiate with respect to layer inputs        \n",
    "        ## For each input value and input gradient\n",
    "            ## Compose the upstream gradient with this input's gradient\n",
    "            ## Set the gradient of the tensor to the composed gradient as necessary\n",
    "            ## Pass the composed gradient backward through structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CHqCz0nKsGB"
   },
   "source": [
    "And here are some sanity checks you can run to make sure that your code is working as intended. In the first check, the outputs should match. In the second, they should be within the specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45Y7ngPUKehB",
    "outputId": "fc6dad07-1d9b-479b-84c6-c4e39167e178"
   },
   "outputs": [],
   "source": [
    "class con: \n",
    "    ## Control set using default PyTorch\n",
    "    ytrue = torch.Tensor(Y0)\n",
    "    ypred = torch_model(torch.Tensor(X0))\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "class exp: \n",
    "    ## Experimental set using your own implementation\n",
    "    ytrue = Tensor(Y0)\n",
    "    ypred = Tensor(con.ypred.detach().numpy())\n",
    "    loss_fn = MSELoss()\n",
    "\n",
    "def ypred_to_loss(ns):\n",
    "    ## Compute loss using the control and experimental namespaces\n",
    "    ns.loss = ns.loss_fn(ns.ypred, ns.ytrue)\n",
    "    return ns.loss\n",
    "\n",
    "## Sanity Check 1: Make sure that the forward pass is the same (i.e. your implementation matches the control)\n",
    "print(ypred_to_loss(con))\n",
    "print(ypred_to_loss(exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9tUAGJkg6I9",
    "outputId": "81ef4fe8-0fca-491e-d37a-4ef9c3131117"
   },
   "outputs": [],
   "source": [
    "## Sanity Check 2: Make sure that the backwards pass is the same\n",
    "\n",
    "con.ypred = con.ypred.detach()\n",
    "con.ypred.requires_grad = True\n",
    "# print(\"Before running backwards:\\n\", con.ypred.grad)\n",
    "ypred_to_loss(con)\n",
    "con.loss.backward()\n",
    "# print(\"After running backwards:\\n\", con.ypred.grad)\n",
    "\n",
    "exp.ypred.grad = None\n",
    "# print(\"Before running backwards:\\n\", np.round(exp.ypred.grad, 4))\n",
    "ypred_to_loss(exp)\n",
    "exp.loss.backward()\n",
    "# print(\"After running backwards:\\n\", np.round(exp.ypred.grad, 4))\n",
    "\n",
    "max_diff = np.max(exp.ypred.grad - con.ypred.grad.detach().numpy())\n",
    "print(f\"Maximum difference {max_diff} should be less than 0.00001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inej4Q37gqN8"
   },
   "source": [
    "### Linear Layer\n",
    "Next, a linear layer!\n",
    "\n",
    "**[TODO]:** Implement the `forward()` pass of a linear layer. \n",
    "\n",
    "**[TODO]:** Calculate (manually) the weight gradients.\n",
    "- Manually differentiate the Dense layer with respect to weights and biases.\n",
    "- Return weight gradient, then bias gradient in that order\n",
    "- HINT: How is differentiating with matrix variables similar to and different from normal differentiation?\n",
    "\n",
    "**[TODO]:** Initalize weights and biases in `_initialize_weight()`.\n",
    "- In a linear layer, we have 2 parameters: weights and biases. \n",
    "- Return two NumPy arrays of the correct shapes according according to the function's arguments. \n",
    "- Return weights and biases, in that order.\n",
    "\n",
    "**[TODO]:** Implement the backward function.\n",
    "- Feel free to only work with the weight gradients, since we do not yet need to support multilayered networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50FnJezypdpt",
    "outputId": "3db15996-701b-46f5-dff7-52d5768e06ba"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Linear(Diffable):\n",
    "\n",
    "    \"\"\"\n",
    "        Standard linear/dense layer.\n",
    "        Subclasses Diffable.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, device=None, dtype=None):\n",
    "        self.w, self.b = self.__class__._initialize_weight(in_features, out_features)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w, self.b\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass for a dense layer! Refer to lecture slides for how this is computed.\"\"\"\n",
    "        # TODO: implement the forward pass and return the outputs\n",
    "        return None\n",
    "\n",
    "    def weight_gradients(self):\n",
    "        \"\"\"Calculating the gradients of the weights and biases!\"\"\"\n",
    "        # TODO: Implement calculation of gradients\n",
    "        wgrads = None\n",
    "        bgrads = None\n",
    "        return (wgrads, bgrads)\n",
    "\n",
    "    def input_gradients(self):\n",
    "        \"\"\"Calculate the gradients of the inputs! (Not necessary for HW1)\"\"\"\n",
    "        return (self.w,)\n",
    "\n",
    "    @staticmethod\n",
    "    def _initialize_weight(input_size, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the values of the weights and biases. You can assume that \n",
    "        bias is a zero-vector and weight is normally-distributed.\n",
    "        \"\"\"\n",
    "        ## TODO: Implement default assumption: zero-init for bias, normal distribution for weights\n",
    "        ## Must return tensors for tracking purposes.\n",
    "        return None\n",
    "\n",
    "    def backward(self, grad=np.array([[1]])):\n",
    "        ## For every weight/bias and weight/bias gradient\n",
    "            ## Compose the upstream gradient with this weight's/bias's gradient\n",
    "            ## Set the gradient of the tensor to the composed gradient if necessary\n",
    "            ## Backpropagate the composed gradient through the structure\n",
    "        pass\n",
    "\n",
    "class con:\n",
    "    ## Control set using regular pytorch\n",
    "    X0 = torch.Tensor(X0)\n",
    "    Y0 = torch.Tensor(Y0)\n",
    "    X0.requires_grad = True\n",
    "    Y0.requires_grad = True\n",
    "    dense = nn.Linear(10, 1)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "class exp:\n",
    "    ## Experimental set using your own implementation\n",
    "    X0 = Tensor(X0)\n",
    "    Y0 = Tensor(Y0)\n",
    "    dense = Linear(10, 1)\n",
    "    dense.w, dense.b = [Tensor(p.detach().numpy()) for p in con.dense.parameters()]\n",
    "    loss_fn = MSELoss()\n",
    "\n",
    "def x_to_loss(ns):\n",
    "    ns.ypred = ns.dense(ns.X0)\n",
    "    ns.loss  = ns.loss_fn(ns.ypred, ns.Y0)\n",
    "    return ns.loss\n",
    "\n",
    "x_to_loss(con)\n",
    "x_to_loss(exp)\n",
    "\n",
    "## Sanity Check 1: Make sure that the forward pass is the same\n",
    "# print(con.ypred)\n",
    "# print(exp.ypred)\n",
    "\n",
    "print(f\"Maximum difference {np.max(con.ypred.detach().numpy() - exp.ypred)} should be less than 0.00001\\n\")\n",
    "\n",
    "print(f\"Losses: Control {con.loss} vs Experimental {exp.loss}\")\n",
    "\n",
    "print('\\nControl Params:',      *list(con.dense.parameters()), sep='\\n')\n",
    "print('\\nExperimental Params:', *list(exp.dense.parameters()), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-v6oUfSJxidG",
    "outputId": "0e5b54b6-841e-4843-da3b-25e030d62a0d"
   },
   "outputs": [],
   "source": [
    "## Sanity Check 2: Make sure that the backwards pass is the same\n",
    "\n",
    "con.X0 = con.X0.detach()\n",
    "con.Y0 = con.Y0.detach()\n",
    "for p in con.dense.parameters():\n",
    "    if p.grad is None: continue\n",
    "    p.grad.detach_()\n",
    "    p.grad = None\n",
    "\n",
    "x_to_loss(con).backward()\n",
    "print(\"After running backwards on weights:\")  \n",
    "print([p.grad for p in con.dense.parameters()])\n",
    "\n",
    "for p in exp.dense.parameters(): p.grad = None\n",
    "x_to_loss(exp).backward()\n",
    "\n",
    "print(\"\\n\" + \"*\" * 100 + \"\\n\")\n",
    "print(\"After running backwards on weights:\")  \n",
    "print([p.grad for p in exp.dense.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQGhTAMgFe_i"
   },
   "source": [
    "## Optimizing With The Gradients\n",
    "\n",
    "To use the gradients we calculated previously, we need an optimizer. The optimizer allows us to update our weights and bias. A simple approach could be to simply subtract the gradient from the weights and bias. In doing so, we follow the gradient in its opposite direction, minimizing loss. This is what is called gradient descent. \n",
    "\n",
    "However, simply subtracting the gradients from the weights could result in the weights changing wildly between each sample, making training longer. To prevent this, we use a learning rate. The learning rate is a hyperparameter that specifies how much a single step updates weights. A smaller learning rate means that the gradients have less of an impact on the weights, and vice versa.\n",
    "\n",
    "Of course, this is just one (simple) approach. We'll cover other optimizers, such as Adam and RMSProp.\n",
    "\n",
    "**[TODO]:** Implement stochastic gradient descent for each parameter using the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5s6o4_WGXhe"
   },
   "outputs": [],
   "source": [
    "class SGD: \n",
    "    \"\"\"\n",
    "        Performs stochastic gradident descent with the specified learning rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr, *args, **kwargs):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "            Reset the gradients.\n",
    "        \"\"\"\n",
    "        pass\n",
    "            \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "            Update paramaters by subtracting the gradient multiplied by the learning rate.\n",
    "        \"\"\"\n",
    "        ## TODO: Implement stochastic grad descent for each parameter\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9m63xegnLnj"
   },
   "source": [
    "Below, you'll use your new implementations to optimize for linear regression manually. FakeTorchModule will also be provided to make some of the mimicking process easier. \n",
    "\n",
    "**[TODO]:** Complete the model and compare this model's performance to the previous `LinearRegression` model -- they should have a similar loss after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6-a0DfvFlnN",
    "outputId": "a5030069-c43e-4f8b-f2d6-2ed17c90d2c6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FakeTorchModule:\n",
    "    \"\"\"\n",
    "        Needed so that we can do manual linear regression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.device = \"\"\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for k,v in self.__dict__.items():\n",
    "            params += getattr(v, 'parameters', lambda: [])()\n",
    "        return params\n",
    "\n",
    "    def train(self):\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = getattr(p, 'required_grad', p.requires_grad)\n",
    "    \n",
    "    def eval(self):\n",
    "        for p in self.parameters():\n",
    "            p.required_grad = p.requires_grad\n",
    "            p.requires_grad = False\n",
    "\n",
    "class ManualRegression(FakeTorchModule):\n",
    "    \"\"\"\n",
    "        Allows us to use our custom Linear layer and SGD optimizer.\n",
    "        Subclasses FakeTorchModule\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__()\n",
    "        ## TODO: Incorporate your custom components in the initialization pipeline. \n",
    "        self.set_learning_rate()\n",
    "\n",
    "    def set_learning_rate(self, learning_rate=0.001):\n",
    "        ## TODO: Use your new SGD component and make changes as appropriate.\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## TODO: Implement the forward function as appropriate. Make changes as necessary\n",
    "        return x\n",
    "\n",
    "class TrainTest2(TrainTest):\n",
    "    # no_grad = torch.no_grad\n",
    "    no_grad = Tensor.no_grad\n",
    "\n",
    "class ManualLinearRegression(ManualRegression, TrainTest2):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__(input_dims, output_dims)\n",
    "        ## TODO: Implement the subclass as appropriate with your own implementations\n",
    "\n",
    "## Train the manual linear regression model\n",
    "model = ManualLinearRegression(10, 1)\n",
    "model.set_learning_rate(0.2)\n",
    "model.train_test(\n",
    "    [[Tensor(X0), Tensor(Y0)]], \n",
    "    [[Tensor(X1), Tensor(Y1)]],\n",
    "    epochs=200\n",
    ");\n",
    "## TODO: Compare this model's performance to the first linear regression model -- they should be similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhxMFrlPOX2J"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6DGrd50k0J5"
   },
   "source": [
    "## Wrapping Up\n",
    "\n",
    "Congratulations, you've finished this assignment! You should now have a better understand of linear regression, loss functions, and optimizers/gradient descent.  Submit the link to your notebook on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "759be6693a164ddeab1e231298c2a01a8302a7c7dfd4e560844dbce42a896f34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
