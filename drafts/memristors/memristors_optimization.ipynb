{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.printoptions(suppress= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaczmarz(A, b, alpha= 1, TOL= 1e-16):\n",
    "    \"\"\"\n",
    "    Implement the Kaczmarz algorithm to solve a system of linear equation.\n",
    "\n",
    "    The algorithm works under the principle of finding an estimated solution (xhat) that satisfies \n",
    "    ||A@xhat - b||^2 < e, with e is the tolerance value.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    \n",
    "    # Initialize the initial solution\n",
    "    X = np.zeros(n)\n",
    "    \n",
    "    k = 0\n",
    "    while True:\n",
    "        # Sampling the i-th row of A and i-th coordinate for b\n",
    "        i = k % m\n",
    "        ai = A[i,:]\n",
    "        bi = b[i]\n",
    "\n",
    "        # Find the solution at the k+1 iteration\n",
    "        Xnew = X + alpha * ((bi - np.dot(ai,X.T)) / np.linalg.norm(ai) ** 2 * ai)\n",
    "        \n",
    "        # Compute the error\n",
    "        err = np.linalg.norm(np.dot(A,Xnew.T) - b) ** 2\n",
    "        if err < TOL:\n",
    "            break\n",
    "        X = Xnew\n",
    "        k += 1\n",
    "    return X\n",
    "\n",
    "def admm(d, A, b, rho= 1, max_iter= 5):\n",
    "    \"\"\"\n",
    "    Implement the alternating direction method of multipliers (ADMM) optimization algorithm to solve a linear program.\n",
    "    The implementation is based on the formulas mentioned in Liu et al. (2018).\n",
    "\n",
    "    The linear program has the following form: min d^Tx, s.t. Ax = b\n",
    "    \"\"\"\n",
    "    d = d.T\n",
    "    b = b.T\n",
    "\n",
    "    # Extract the number of variables and constraints from the matrix dimensions\n",
    "    no_of_vars = A.shape[1]\n",
    "    no_of_constraints = A.shape[0]\n",
    "\n",
    "    # Initialize the dual variables y and mu\n",
    "    y  = np.random.normal(size= (1,no_of_vars))\n",
    "    mu = np.random.normal(size= (1,no_of_vars))\n",
    "\n",
    "    # Construct the augmented Lagrangian matrix\n",
    "    C = np.block([\n",
    "        [rho * np.eye(no_of_vars), A.T],\n",
    "        [A, np.zeros((no_of_constraints,no_of_constraints))]\n",
    "                ])\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # Solve for the primal variable x\n",
    "        alpha = y - (1/rho) * (mu + d)\n",
    "        m = np.block([rho * alpha, b]).T\n",
    "        x = kaczmarz(C, m)[: no_of_vars]\n",
    "\n",
    "        # Apply soft-thresholding to update the dual variable y\n",
    "        beta = x + (1/rho) * mu.T\n",
    "        beta[beta < 0] = 0\n",
    "        y = beta.T\n",
    "\n",
    "        # Update the dual variable mu\n",
    "        mu = mu + rho * (x.T - y)\n",
    "\n",
    "    return (x,y,mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([-1, -2, -4, 0, 0, 0])\n",
    "A = np.array([\n",
    "    [3, 1, 5, 1, 0, 0],\n",
    "    [1, 4, 1, 0, 1, 0],\n",
    "    [2, 0, 2, 0, 0, 1]])\n",
    "b = np.array([10, 8, 7])\n",
    "\n",
    "x, _ , _ = admm(d, A, b)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
