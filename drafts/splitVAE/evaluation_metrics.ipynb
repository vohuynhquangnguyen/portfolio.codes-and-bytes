{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid(observed, generated):\n",
    "    \"\"\"Implement the Frechet inception distance.\"\"\"\n",
    "    first_term = np.linalg.norm(np.mean(observed, axis= 1) - np.mean(generated, axis= 1))\n",
    "    second_term = np.trace(np.cov(observed) + np.cov(observed) - 2 * np.sqrt(np.cov(observed) * np.cov(observed)))\n",
    "    score = first_term + second_term\n",
    "    return score\n",
    "\n",
    "\n",
    "def emp_cum_dist(data):\n",
    "    \"\"\"\n",
    "    Compute the empirical cumulative distribution function (ecdf) of a normalized vector.\n",
    "    The Freedman-Diaconis Rule is employed to compute the number of bins for constructing the empirical probability density function (epdf).\n",
    "    \"\"\"\n",
    "    normalized_data = data - np.mean(data) / np.std(data, ddof= 1)\n",
    "    \n",
    "    numerator = np.max(normalized_data) - np.min(normalized_data)\n",
    "    denominator = 2 * np.subtract(np.percentile(normalized_data, [75, 25])) / np.power(len(normalized_data),(1/3))\n",
    "    counts, _ = np.histogram(normalized_data, bins= numerator // denominator)\n",
    "    epdf = counts / sum(counts)  \n",
    "    ecdf = np.cumsum(epdf) \n",
    "\n",
    "    return ecdf\n",
    "\n",
    "def cprs(observed, generated):\n",
    "    \"\"\"Implement the empirical continuous probability ranked score.\"\"\"\n",
    "    observed_ecdf = emp_cum_dist(observed)\n",
    "    generated_ecdf = emp_cum_dist(generated)\n",
    "    score  = sum(np.power(observed_ecdf - generated_ecdf),2)\n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
