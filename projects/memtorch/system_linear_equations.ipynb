{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A system of five linear equations has the following expression in matrix notation:\n",
        "$$\n",
        "\\begin{bmatrix} \n",
        "y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ y_5 \n",
        "\\end{bmatrix} = \n",
        "\n",
        "\\begin{bmatrix} \n",
        "    w_{1,1} & w_{1,2} & w_{1,3} & w_{1,4} & w_{1,5} \\\\ \n",
        "    w_{2,1} & w_{2,2} & w_{2,3} & w_{2,4} & w_{2,5} \\\\ \n",
        "    w_{3,1} & w_{3,2} & w_{3,3} & w_{3,4} & w_{3,5} \\\\ \n",
        "    w_{4,1} & w_{4,2} & w_{4,3} & w_{4,4} & w_{4,5} \\\\ \n",
        "    w_{5,1} & w_{5,2} & w_{5,3} & w_{5,4} & w_{5,5} \\\\ \n",
        "\\end{bmatrix} \n",
        "\n",
        "\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{bmatrix} +\n",
        "\n",
        "\\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\\\ b_5 \\end{bmatrix}\n",
        "$$\\\n",
        "\n",
        "We can simplify the above expression to:\n",
        "$$\n",
        "\\mathbf{y} = \\mathbf{W}\\mathbf{x} + \\mathbf{b}\n",
        "$$\n",
        "with \n",
        "* $\\mathbf{x}$ is a column vector representing our inputs, whose size is (5,1).\n",
        "* $\\mathbf{y}$ is a column vector representing our outputs, whose size is (5,1).\n",
        "* $\\mathbf{W}$ is a matrix representing our coefficients, whose size is (5,5).\n",
        "* $\\mathbf{b}$ is a column vector representing our biases, whose size is (5,1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jVH_tu3tv5E4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class LinearLayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.weights = np.random.randn(input_size, output_size)\n",
        "        self.bias = np.zeros((input_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.mm(x, self.weights) + self.bias\n",
        "    \n",
        "layer = LinearLayer(5, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag8Z6Rn_v5E8"
      },
      "source": [
        "## 3. Conversion of a Deep Neural Network to a Memristive Deep Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyt9qHvAv5E9"
      },
      "source": [
        "Within MemTorch, `memtorch.mn.Module.patch_model` can be used to convert DNNs to a MDNNs. Prior to conversion, a memristive device model must be defined and characterized in part (prior to the introduction of other non-ideal device characteristics).\n",
        "\n",
        "In the cell below:\n",
        "* A reference (base) memristor model from `memtorch.bh.memristor` is defined.\n",
        "* Optional reference memristor keyword arguments are set.\n",
        "* A `memtorch.bh.memristor.Memristor` object is instantiated\n",
        "* The hysteresis loop of the instantiated memristor object is generated/plotted.\n",
        "* The bipolar switching behaviour of the instantiated memristor object is generated/plotted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRMGKP-lv5E-"
      },
      "outputs": [],
      "source": [
        "reference_memristor = memtorch.bh.memristor.VTEAM\n",
        "reference_memristor_params = {'time_series_resolution': 1e-10}\n",
        "memristor = reference_memristor(**reference_memristor_params)\n",
        "memristor.plot_hysteresis_loop()\n",
        "memristor.plot_bipolar_switching_behaviour()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0kLErl0v5FC"
      },
      "source": [
        "In the cell below, the trained DNN from Section 2 is converted to an equivalent MDNN, where all convolutional layers are replaced with memristive-equivalent layers. While only *Conv2d* layers are converted for demonstration purposes, we note that MemTorch currently supports conversion of *Conv1d*, *Conv2d*, *Conv3d*, and *Linear* layers. Specifically:\n",
        "* `memtorch.bh.map.Parameter.naive_map` is used to convert the weights within all `torch.nn.Conv2d` layers to equivalent conductance values, to be programmed to the two memristive devices used to represent each weight (positive and negative, respectively).\n",
        "* `tile_shape` is set to (128, 128), so that modular crossbar tiles of size 128x128 are used to represent weights.\n",
        "* `ADC_resolution` is set to 8 to set the bit width of all emulated Analogue to Digital Converters (ADC).\n",
        "* `ADC_overflow` is used to set the initial overflow rate of each ADC.\n",
        "* `quant_method` is used to set the quantization method used (linear, by default).\n",
        "* `transistor` is set to `True`, so a 1T1R arrangement is simulated.\n",
        "* `programming_routine` is set to `None` to skip device-level simulation of the programming routine.\n",
        "\n",
        "\n",
        "\n",
        "We note if `transistor` is `False` `programming_routine` must not be `None`. In which case, device-level simulation is performed for each device using `memtorch.bh.crossbar.gen_programming_signal` and `memtorch.bh.memristor.Memristor.simulate`, which use finite differences to model internal device dynamics. As `scheme` is not defined, a double-column parameter representation scheme is adopted. Finally, `max_input_voltage` is 0.3, meaning inputs to each layer are encoded between -0.3V and +0.3V."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJWSTW5Qv5FD"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from memtorch.mn.Module import patch_model\n",
        "from memtorch.map.Input import naive_scale\n",
        "from memtorch.map.Parameter import naive_map\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load('trained_model.pt'), strict=False)\n",
        "patched_model = patch_model(copy.deepcopy(model),\n",
        "                          memristor_model=reference_memristor,\n",
        "                          memristor_model_params=reference_memristor_params,\n",
        "                          module_parameters_to_patch=[torch.nn.Conv2d],\n",
        "                          mapping_routine=naive_map,\n",
        "                          transistor=True,\n",
        "                          programming_routine=None,\n",
        "                          tile_shape=(128, 128),\n",
        "                          max_input_voltage=0.3,\n",
        "                          scaling_routine=naive_scale,\n",
        "                          ADC_resolution=8,\n",
        "                          ADC_overflow_rate=0.,\n",
        "                          quant_method='linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WeMLQXBH0de"
      },
      "source": [
        "In the cell below, all patched `torch.nn.Conv2d` layers are tuned using linear regression. A randomly generated tensor of size (8, `self.in_channels`, 32, 32) is propagated through each memristive layer and each legacy layer (accessible using `layer.forward_legacy`). `sklearn.linear_model.LinearRegression` is used to determine the coefficient and intercept between the linear relationship of each set of outputs, which is used to define the `transform_output` lamdba function, that maps the output of each layer to their equivalent representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mam3ggffv5FG"
      },
      "outputs": [],
      "source": [
        "patched_model.tune_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN_U95V_H0de"
      },
      "source": [
        "Finally, in the cell below, the converted and tuned MDNN is benchmarked using the MNIST test data set.\n",
        "*Note: This cell may take a considerable amount of time to run.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5F0muXPv5FK"
      },
      "outputs": [],
      "source": [
        "print(test(patched_model, test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV8IJSH6v5FN"
      },
      "source": [
        "## 4. Modeling Non-Ideal Device Characteristics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4H9f4d248V7"
      },
      "source": [
        "\n",
        "Non-ideal device characteristics can either be encapsulated within device specific memristive models, or introduced to base (generic) models after conversion, using `memtorch.bh.nonideality.NonIdeality.apply_nonidealities`. Currently, the following non-ideal device characteristics are supported:\n",
        "* `memtorch.bh.nonideality.DeviceFaults`\n",
        "* `memtorch.bh.nonideality.Endurance` and `memtorch.bh.nonideality.Retention`\n",
        "* `memtorch.bh.nonideality.FiniteConductanceStates`\n",
        "* `memtorch.bh.nonideality.NonLinear`\n",
        "\n",
        "Stochastic parameters, used to model process variances, can be defined using `memtorch.bh.StochaticParameter`. The introduction of each type of non ideal device characteristic is demonstrated below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pewV5scsH2ZT"
      },
      "source": [
        "### 4.1 Modeling Device Faults\n",
        "\n",
        "Memristive devices are susceptible to failure, by either failing to eletroform at a pristine state, or becoming stuck at high or low resistance states. MemTorch incorporates a specific function for accounting for device failure, `memtorch.bh.nonideality.DeviceFaults`.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* `lrs_proportion` is set to 0.25, so that 25% of devices are assumed to fail to a low resistance state.\n",
        "* `hrs_proportion` is set to 0.10, so that 15% of devices are assumed to fail to a high resistance state.\n",
        "\n",
        "It is assumed that the total proportion of devices set to a high resistance state is equal to the proportion of devices that fail to eletroform at pristine states plus the proportion of devices stuck at a high resistance state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEJmY_ENH0dg"
      },
      "outputs": [],
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.DeviceFaults],\n",
        "                                  lrs_proportion=0.25,\n",
        "                                  hrs_proportion=0.10,\n",
        "                                  electroform_proportion=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTxU1vckH0dg"
      },
      "outputs": [],
      "source": [
        "print(test(patched_model_, test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Vcpuuw5D_S"
      },
      "source": [
        "### 4.2 Modeling Device Endurance and Retention\n",
        "\n",
        "Memristive devices possess non-ideal endurance and retention properties, which should be accounted for. MemTorch incorporates specific functions for accounting for device endurance and retention characteristics, `memtorch.bh.nonideality.Endurance`, and `memtorch.bh.nonideality.Retention`, respectively.\n",
        "\n",
        "All endurance and retention models are defined in `memtorch.bh.nonideality.endurance_retention_models`.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* `x`, the number of SET-RESET cycles is set to be equal to 10,000.\n",
        "* Endurance characteristics are accounted for using `memtorch.bh.nonideality.NonIdeality.Endurance` and `memtorch.bh.nonideality.endurance_retention_models.model_endurance_retention`.\n",
        "* `operation_mode` within `endurance_model_kwargs` is set to `sudden`, so that sudden failure is modeled, and various other model arguments are set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4thsaVDEv5FS"
      },
      "outputs": [],
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.Endurance],\n",
        "                                  x=1e4,\n",
        "                                  endurance_model=memtorch.bh.nonideality.endurance_retention_models.model_endurance_retention,\n",
        "                                  endurance_model_kwargs={\n",
        "                                        \"operation_mode\": memtorch.bh.nonideality.endurance_retention_models.OperationMode.sudden,\n",
        "                                        \"p_lrs\": [1, 0, 0, 0],\n",
        "                                        \"stable_resistance_lrs\": 100,\n",
        "                                        \"p_hrs\": [1, 0, 0, 0],\n",
        "                                        \"stable_resistance_hrs\": 1000,\n",
        "                                        \"cell_size\": 10,\n",
        "                                        \"temperature\": 350,\n",
        "                                  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl7_hStXH0dh"
      },
      "outputs": [],
      "source": [
        "print(test(patched_model_, test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KykmIom1H0dh"
      },
      "source": [
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* `time`, the retention time, is set to be equal to 1,000s.\n",
        "* Retention characteristics are accounted for using `memtorch.bh.nonideality.NonIdeality.Retention` and `memtorch.bh.nonideality.endurance_retention_models.model_conductance_drift`.\n",
        "* `initial_time` within `retention_model_kwargs`, the initial time, is set to be equal to 1s.\n",
        "* `drift_coefficient` within `retention_model_kwargs` is set to be equal to 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTNNAcCiH0dh"
      },
      "outputs": [],
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.Retention],\n",
        "                                  time=1e3,\n",
        "                                  retention_model=memtorch.bh.nonideality.endurance_retention_models.model_conductance_drift,\n",
        "                                  retention_model_kwargs={\n",
        "                                        \"initial_time\": 1,\n",
        "                                        \"drift_coefficient\": 0.1,\n",
        "                                  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV1ANo6-H0di"
      },
      "outputs": [],
      "source": [
        "print(test(patched_model_, test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR03gyJVH0di"
      },
      "source": [
        "### 4.3 Modeling a Finite Number of Conductance States\n",
        "\n",
        "Realistic memristive devices are non-ideal and have a finite number of stable discrete electrically switchable conductance states, bounded by a low conductance semiconducting state, and a high-conductance metallic state. MemTorch incorporates a specific function for accounting for devices with a finite number of conductance states, `memtorch.bh.nonideality.FiniteConductanceStates`.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* A finite number of conductance states are accounted for using `memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates`.\n",
        "* `conductance_states` is set to be equal to 5, to model 5 evenly-distributed conductance states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH0e7AtWH0di"
      },
      "outputs": [],
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.FiniteConductanceStates],\n",
        "                                  conductance_states=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA6Bc-PPH0di"
      },
      "outputs": [],
      "source": [
        "print(test(patched_model_, test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FBLj9-mH0di"
      },
      "source": [
        "### 4.4 Modeling Non-Linear Device Characteristics\n",
        "\n",
        "Non-ideal memristive devices have non-linear I/V device characteristics, especially at high voltages, which are difficult to accurately and efficiently model. The `memtorch.bh.nonideality.NonLinear.apply_non_linear` function can be used to efficiently model non-linear device I/V characteristics during inference for devices with an infinite number of discrete conductance states, and for devices with a finite number of conductance states.\n",
        "\n",
        "For cases where devices are not simulated using their internal dynamics, it is assumed that the change in conductance during read cycles is negligible.\n",
        "\n",
        "Within MemTorch, `memtorch.bh.nonideality.NonLinear.apply_non_linear` uses two methods to effectively model non-linear device I/V characteristics:\n",
        "\n",
        "1. During inference, each device is simulated for timesteps of duration `device.time_series_resolution` using `device.simulate`.\n",
        "2. Post weight mapping and programming, the I/V characteristics of each device are determined using a single reset voltage sweep.\n",
        "\n",
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* Non-linear device characteristics are accounted for using `memtorch.bh.nonideality.NonLinear`.\n",
        "* `simulate` is set to be equal to `True`, so during inference each device is simulated.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-0leLIdH0di"
      },
      "outputs": [],
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.NonLinear],\n",
        "                                  simulate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AWwwouiH0dj"
      },
      "outputs": [],
      "source": [
        "print(test(patched_model_, test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2W039iPH0dj"
      },
      "source": [
        "In the cell below:\n",
        "* The original patched model is copied using `copy.deepcopy`.\n",
        "* Non-linear device characteristics are accounted for using `memtorch.bh.nonideality.NonLinear`.\n",
        "* `simulate` is not set, so the I/V characteristics of each device are determined using a single reset voltage sweep.\n",
        "* `sweep_duration` is set to be equal to 2s.\n",
        "* `sweep_voltage_signal_amplitude` is set to be equal to 1V.\n",
        "* `sweep_voltage_signal_frequency` is set to be equal to 0.5Hz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZOh4WJZH0dj"
      },
      "outputs": [],
      "source": [
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "patched_model_ = apply_nonidealities(copy.deepcopy(patched_model),\n",
        "                                  non_idealities=[memtorch.bh.nonideality.NonIdeality.NonLinear],\n",
        "                                  sweep_duration=2,\n",
        "                                  sweep_voltage_signal_amplitude=1,\n",
        "                                  sweep_voltage_signal_frequency=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnPpuvPaH0dj"
      },
      "outputs": [],
      "source": [
        "print(test(patched_model_, test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTA0KyOEH0dj"
      },
      "source": [
        "### 4.5 Modeling Stochastic Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoS7ZHhdH0dk"
      },
      "source": [
        "MemTorch supports the usage of stochastic parameters for higher flexibility to simply account for process variances using `memtorch.bh.StochasticParameter.StochasticParameter`. Stochastic parameters can be used when defining device characteristics.\n",
        "\n",
        "In the cell below:\n",
        "* A memristor object is characterised using stochastic parameters defining low and high resistance states.\n",
        "* The memristor object is instantiated, and the hysteresis loop and bipolar switching behaviour of the instantiated memristor object is generated/plotted.\n",
        "\n",
        "Each time the memristor object is instantiated, stochastic parameters will be resampled.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Kozl3dH0dk"
      },
      "outputs": [],
      "source": [
        "import memtorch\n",
        "\n",
        "reference_memristor = memtorch.bh.memristor.VTEAM\n",
        "reference_memristor_params = {'time_series_resolution': 1e-10,\n",
        "                              'r_off': memtorch.bh.StochasticParameter(loc=1000, scale=200, min=2),\n",
        "                              'r_on': memtorch.bh.StochasticParameter(loc=5000, scale=sigma, min=1)}\n",
        "\n",
        "memristor = reference_memristor(**reference_memristor_params)\n",
        "memristor.plot_hysteresis_loop()\n",
        "memristor.plot_bipolar_switching_behaviour()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSOaAOQAH0dk"
      },
      "source": [
        "## Final Remarks\n",
        "A complete API is avaliable [here](https://memtorch.readthedocs.io/). To learn how to use MemTorch, and to reproduce results of ‘_MemTorch: An Open-source Simulation Framework for Memristive Deep Learning Systems_’, we provide numerous tutorials in the form of Jupyter notebooks [here](https://memtorch.readthedocs.io/en/latest/tutorials.html).\n",
        "\n",
        "Current issues, feature requests and improvements are welcome, and are tracked using: https://github.com/coreylammie/MemTorch/projects/1. These should be reported [here](https://github.com/coreylammie/MemTorch/issues)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
