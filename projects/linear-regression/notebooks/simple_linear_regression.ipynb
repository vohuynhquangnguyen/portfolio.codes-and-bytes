{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q6zBs096pHhT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import t, f, norm\n",
        "np.set_printoptions(precision= 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lu8wI3zxpHhV"
      },
      "outputs": [],
      "source": [
        "class SLR():\n",
        "    \"\"\"\n",
        "    Author: Lucius Vo <https://github.com/vohuynhquangnguyen>\n",
        "    Construct a simple linear regression (SLR) model and conduct required estimations and hypothesis test.\n",
        "    Methods of estimating the model's parameters and hypothesis test are based on Mendenhall and Sincich (2013, p.96-165).\n",
        "\n",
        "    References:\n",
        "    1. Mendenhall, William, Sincich, Terry T. A Second Course in Statistics - Regression Analysis (7th Edition). Pearson, 2013\n",
        "    2. Montgomery, Douglas C., Runger, George C. Applied Statistics and Probability for Engineer (7th Edition). Wiley, 2018\n",
        "    \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        super(SLR, self).__init__\n",
        "        pass\n",
        "\n",
        "    def load_data(self, src: str, X_header: str, Y_header: str):\n",
        "        \"\"\"\n",
        "        Load the dataset from a .csv file using Pandas file handler.\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(src)\n",
        "        self.X = np.array(df[X_header])\n",
        "        self.Y = np.array(df[Y_header])\n",
        "        pass\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Compute the parameters of the fitted model using the ordinary least square (OLS) method.\n",
        "        \"\"\"\n",
        "        self.Xbar = np.mean(self.X)\n",
        "        self.Ybar = np.mean(self.Y)\n",
        "\n",
        "        self.SS_xx = np.sum((np.power(x - self.Xbar, 2) for x in self.X), axis= -1)\n",
        "        self.SS_yy = np.sum((np.power(y - self.Ybar, 2) for y in self.Y), axis= -1)\n",
        "        self.SS_xy = np.sum(((x - self.Xbar) * (y - self.Ybar) for (x,y) in zip(self.X,self.Y)),\n",
        "                            axis= -1)\n",
        "\n",
        "        self.B1hat = self.SS_xy / self.SS_xx\n",
        "        self.B0hat = self.Ybar - self.B1hat * self.Xbar\n",
        "        pass\n",
        "\n",
        "    def estimate_variance_residuals(self):\n",
        "        \"\"\"\n",
        "        Estimate the variance of residuals\n",
        "        \"\"\"\n",
        "        self.e = np.array([y - (self.B0hat + self.B1hat * x) for (x,y) in zip(self.X, self.Y)])\n",
        "        self.SS_E = np.sum((np.power(y - (self.B0hat + self.B1hat * x), 2) for (x,y) in zip(self.X, self.Y)),\n",
        "                           axis= -1)\n",
        "        self.s2 = self.SS_E / (len(self.Y) - 2)\n",
        "        self.SE_B1hat = np.power(self.s2 / self.SS_xx, 1/2)\n",
        "        self.SE_B0hat = np.power(self.s2 * ( 1 / len(self.Y) + self.Xbar ** 2 / self.SS_xx), 1/2)\n",
        "        pass\n",
        "\n",
        "    def ANOVA(self):\n",
        "        \"\"\"\n",
        "        Conduct the analysis of variance (ANOVA) on the fitted model.\n",
        "        \"\"\"\n",
        "        self.SS_R = np.sum((np.power((self.B0hat + self.B1hat * x) - self.Ybar, 2) for x in self.X),\n",
        "                           axis= -1)\n",
        "        self.SS_T = self.SS_R + self.SS_E\n",
        "        self.Rsquare = self.SS_R / self.SS_T\n",
        "        pass\n",
        "\n",
        "    def conduct_statistical_inference(self, level: float = 0.95):\n",
        "        \"\"\"\n",
        "        Conduct the hypothesis tests on the fitted model at the significant level (default is 95%).\n",
        "        \"\"\"\n",
        "        self.estimate_variance_residuals()\n",
        "        self.ANOVA()\n",
        "\n",
        "        # Test on the estimated slope and intercept (two-tailed T-test):\n",
        "        t_c = t.ppf((1 - level)/2, df = len(self.Y) - 2)\n",
        "        self.T_B1hat = (self.B1hat - 0) / self.SE_B1hat\n",
        "        self.T_B0hat = (self.B0hat - 0) / self.SE_B0hat\n",
        "\n",
        "        self.pval_B1 = t.sf(abs(self.T_B1hat), len(self.Y) - 2) * 2\n",
        "        self.pval_B0 = t.sf(abs(self.T_B0hat), len(self.Y) - 2) * 2\n",
        "\n",
        "        # Test on the Pearson correlation coefficient (two-tailed T-test):\n",
        "        self.r = np.power(self.SS_xy / (self.SS_xx * self.SS_yy), 1/2)\n",
        "        self.t_r = np.power(self.r * ((self.n - 2) / (1 - self.r ** 2)), 1/2)\n",
        "        self.pval_r = t.sf(abs(self.t_r), df = self.n - 2) * 2\n",
        "\n",
        "        # Test on the significant of regression (two-tailed T-test):\n",
        "        self.F = (self.SS_R / 1) / (self.SS_E / (self.n - 2))\n",
        "        self.pval_F = f.sf(self.F, 1, self.n - 2)\n",
        "        pass\n",
        "\n",
        "    def compute_intervals(self, level: float = 0.95):\n",
        "        \"\"\"\n",
        "        Compute the confidence intervals and the prediction intervals:\n",
        "        \"\"\"\n",
        "        t_c = t.ppf((1 - level)/2, df = len(self.Y) - 2)\n",
        "\n",
        "        # Confidence interval for the parameters:\n",
        "        self.B0hat_CI_lwr = self.B0hat - t_c * self.SE_B0hat\n",
        "        self.B0hat_CI_upr = self.B0hat + t_c * self.SE_B0hat\n",
        "\n",
        "        self.B1hat_CI_lwr = self.B1hat - t_c * self.SE_B1hat\n",
        "        self.B1hat_CI_upr = self.B1hat + t_c * self.SE_B1hat\n",
        "\n",
        "        # Confidence interval of mean response at x:\n",
        "        self.func = lambda x: self.B0hat + self.B1hat * x\n",
        "        self.Yhat_CI_lwr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x - t_c * np.sqrt(self.SE * (1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "        self.Yhat_CI_upr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x + t_c * np.sqrt(self.SE * (1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "\n",
        "        # Prediction interval of mean response at x:\n",
        "        self.yhat_PI_lwr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x - t_c * np.sqrt(self.SE * (1 + 1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "        self.yhat_PI_upr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x + t_c * np.sqrt(self.SE * (1 + 1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "        pass\n",
        "\n",
        "    def visualize(self):\n",
        "        \"\"\"\n",
        "        Visualize the entire analysis process:\n",
        "        \"\"\"\n",
        "\n",
        "        # Visualize the distribution of the dataset:\n",
        "        fig, axs = plt.subplots(1, 2, figsize = (8,4), dpi = 100)\n",
        "        nbins = \\\n",
        "         (np.max(self.X, axis= -1) - np.min(self.X, axis= -1)) * np.power(len(self.Y), 1/3) / (3.49 * np.std(self.X, ddof= 1))\n",
        "        sns.histplot(self.X, bins = int(nbins), ax = axs[0])\n",
        "        axs[0].set_title(f\"Histogram of {self.X_header}\")\n",
        "        axs[0].grid(True)\n",
        "\n",
        "        nbins = \\\n",
        "         (np.max(self.Y, axis= -1) - np.min(self.Y,axis= -1)) * np.power(len(self.Y), 1/3) / (3.49 * np.std(self.Y, ddof= 1))\n",
        "        sns.histplot(self.Y, bins = int(nbins), ax = axs[1])\n",
        "        axs[1].set_title(f\"Histogram of {self.Y_header}\")\n",
        "        axs[1].grid(True)\n",
        "        fig.tight_layout()\n",
        "\n",
        "        # Visualize the regression analysis:\n",
        "        fig, axs = plt.subplots(1, 3, figsize = (15,4), dpi = 100)\n",
        "        sns.scatterplot({f\"{self.X_header}\": self.X, f\"{self.Y_header}\": self.Y},\n",
        "                        x =  f\"{self.X_header}\", y = f\"{self.Y_header}\", ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.func(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'solid', linewidth = 1.0, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.Yhat_CI_lwr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dashdot', linewidth = 0.75, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.Yhat_CI_upr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dashdot', linewidth = 0.75, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_PI_lwr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dotted', linewidth = 0.55, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_PI_upr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dotted', linewidth = 0.55, ax = axs[0])\n",
        "        axs[0].set_title(f\"{self.Y_header} vs. {self.X_header}\")\n",
        "        axs[0].grid(True)\n",
        "\n",
        "        # Visualize the residual analysis:\n",
        "        sns.scatterplot({f\"{self.Y_header}\": self.Y, \"Residual\": self.e},\n",
        "                        x = f\"{self.Y_header}\", y = \"Residual\",\n",
        "                        ax = axs[1])\n",
        "        axs[1].axhline(y = 0, color = 'red', linestyle = 'dashed', linewidth = 1.0)\n",
        "        axs[1].set_title(f\"Residual Plot\")\n",
        "        axs[1].grid(True)\n",
        "\n",
        "        rank = np.array([(i - 0.375) / (self.n + 0.25) for i in range(1, self.n + 1)])\n",
        "        z_e = np.array([norm.ppf(i) for i in rank])\n",
        "        sns.scatterplot({\"Residual\": sorted(self.e), \"Z-score\": z_e},\n",
        "                        x = \"Residual\", y = \"Z-score\", ax = axs[2])\n",
        "        axs[2].set_title(f\"Residual Normality Plot\")\n",
        "        axs[2].grid(True)\n",
        "        fig.tight_layout()\n",
        "        pass\n",
        "\n",
        "    def run_regression_analysis(self):\n",
        "        \"\"\"\n",
        "        Generate a full analysis report.\n",
        "        \"\"\"\n",
        "        self.fit()\n",
        "        self.estimate_variance_residuals()\n",
        "        self.conduct_statistical_inference()\n",
        "        self.compute_intervals()\n",
        "        self.visualize()\n",
        "\n",
        "        ##\n",
        "        # Generate a report:\n",
        "        #\n",
        "        print(f\"\\nModel: {self.Y_header} ~ {self.X_header}\")\n",
        "        print(f\"\\n\\t  Min \\t Q1 \\t Median \\t Q3 \\tMax\")\n",
        "        print(f\"Residuals: {self.e_min} \\t {self.e_q1} \\t {self.e_q2} \\t {self.e_q3} \\t {self.e_max}\")\n",
        "\n",
        "        print(f\"\\n\\t  Coefficient \\t Std. Error \\t Lower-bound CI \\t Upper-bound CI \\t t-Statistic \\t Pr(>|t|) at {100 * self.level}%\")\n",
        "        print(f\"Intercept: {self.b0hat} \\t {self.se_b0hat} \\t {self.b0hat_lwr} \\t {self.b0hat_upr} \\t {self.t_b0hat} \\t {self.pval_b0}\")\n",
        "        print(f\"{self.X_header}: {self.b1hat} \\t {self.se_b1hat} \\t {self.b1hat_lwr} \\t {self.b1hat_upr} \\t {self.t_b1hat} \\t {self.pval_b1}\")\n",
        "\n",
        "        print(f\"\\nResidual Std. Error: {self.e_stde } on {len(self.Y) - 2} DF\")\n",
        "        print(f\"R-square: {self.Rsquare}\")\n",
        "        print(f\"Pearson correlation coef.: {self.r}, p-value: {self.pval_r}\")\n",
        "        print(f\"F-statistic: {self.F} on 1 predictor and {len(self.Y) - 2} DF, p-value: {self.pval_F}\")\n",
        "\n",
        "        self.visualize()\n",
        "\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "g95BKXbqpHhX",
        "outputId": "a9f723d4-1f8b-4c31-adea-cfb4f8c5280b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-589dc8b16e7d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mslr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mslr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dataset/TAMPALMS.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Market_Val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sale_Price\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mslr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_regression_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-643a244e4c32>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, src, X_header, Y_header)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mLoad\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m \u001b[0mfile\u001b[0m \u001b[0musing\u001b[0m \u001b[0mPandas\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \"\"\"\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_header\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_header\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/TAMPALMS.csv'"
          ]
        }
      ],
      "source": [
        "slr = SLR()\n",
        "slr.load_data(\"./dataset/TAMPALMS.csv\", \"Market_Val\", \"Sale_Price\")\n",
        "slr.run_regression_analysis()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}