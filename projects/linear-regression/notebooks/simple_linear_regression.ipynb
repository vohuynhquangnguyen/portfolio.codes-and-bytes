{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q6zBs096pHhT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import t, f, norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lu8wI3zxpHhV"
      },
      "outputs": [],
      "source": [
        "class SLR():\n",
        "    \"\"\"\n",
        "    Author: Lucius Vo <https://github.com/vohuynhquangnguyen>\n",
        "    Construct a simple linear regression (SLR) model and conduct required estimations and hypothesis test.\n",
        "    Methods of estimating the model's parameters and hypothesis test are based on Mendenhall and Sincich (2013, p.96-165).\n",
        "\n",
        "    References:\n",
        "    1. Mendenhall, William, Sincich, Terry T. A Second Course in Statistics - Regression Analysis (7th Edition). Pearson, 2013\n",
        "    2. Montgomery, Douglas C., Runger, George C. Applied Statistics and Probability for Engineer (7th Edition). Wiley, 2018\n",
        "    \"\"\"\n",
        "    def __init__(self, src: str, predictor: str, response: str) -> None:\n",
        "        super(SLR, self).__init__\n",
        "        self.src = src\n",
        "        self.predictor = predictor\n",
        "        self.response = response\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Load the dataset from a .csv file using Pandas file handler.\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(self.src)\n",
        "        self.X = np.array(df[self.predictor])\n",
        "        self.Y = np.array(df[self.response])\n",
        "        pass\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Compute the parameters of the fitted model using the ordinary least square (OLS) method.\n",
        "        \"\"\"\n",
        "        self.xbar = np.mean(self.X)\n",
        "        self.ybar = np.mean(self.Y)\n",
        "\n",
        "        self.SS_xx = sum((x - self.x_bar) ** 2 for x in self.X)\n",
        "        self.SS_yy = sum((y - self.y_bar) ** 2 for y in self.Y)\n",
        "        self.SS_xy = sum((x - self.x_bar) * (y - self.y_bar) for (x,y) in zip(self.X, self.Y))\n",
        "\n",
        "        self.b1hat = self.SS_xy / self.SS_xx\n",
        "        self.b0hat = self.y_bar - self.b1_hat * self.x_bar\n",
        "        pass\n",
        "\n",
        "    def compute_standard_error(self):\n",
        "        \"\"\"\n",
        "        Compute the standard errors of the fitted model's parameters (slope and intercept).\n",
        "        \"\"\"\n",
        "        self.n = len(self.Y)\n",
        "        self.e = np.array([y - (self.b0_hat + self.b1_hat * x) for (x,y) in zip(self.X, self.Y)])\n",
        "        self.SS_E = sum((y - (self.b0_hat + self.b1_hat * x)) ** 2 for (x,y) in zip(self.X, self.Y))\n",
        "        self.se = self.SS_E / (self.n - 2)\n",
        "        self.se_b1_hat = (self.se / self.SS_xx) ** (1/2)\n",
        "        self.se_b0_hat = (self.se * ( 1 / self.n + self.x_bar ** 2 / self.SS_xx)) ** (1/2)\n",
        "        pass\n",
        "\n",
        "    def ANOVA(self):\n",
        "        \"\"\"\n",
        "        Conduct the analysis of variance (ANOVA) on the fitted model.\n",
        "        \"\"\"\n",
        "        self.SS_R = sum(((self.b0_hat + self.b1_hat * x) - self.y_bar) ** 2 for x in self.X)\n",
        "        self.SS_T = self.SS_R + self.SS_E\n",
        "        self.Rsquare = self.SS_R / self.SS_T\n",
        "        pass\n",
        "\n",
        "    def hypothesis_test(self, level: float = 0.95):\n",
        "        \"\"\"\n",
        "        Conduct the hypothesis test on the fitted model at the significant level (default is 95%).\n",
        "        \"\"\"\n",
        "        self.compute_standard_error()\n",
        "\n",
        "        ##\n",
        "        # Hypothesis test on the fitted model's parameters (two-tailed T-test):\n",
        "        #\n",
        "        self.t_b1hat = (self.b1_hat - 0) / self.se_b1_hat\n",
        "        self.t_b0hat = (self.b0_hat - 0) / self.se_b0_hat\n",
        "\n",
        "        self.t_c = t.ppf(level, df = self.n - 2)\n",
        "        self.pval_b1 = t.sf(abs(self.t_b1_hat), self.n - 2) * 2\n",
        "        self.pval_b0 = t.sf(abs(self.t_b0_hat), self.n - 2) * 2\n",
        "\n",
        "        ##\n",
        "        # Hypothesis test on the Pearson correlation coefficient (two-tailed T-test):\n",
        "        #\n",
        "        self.r = self.SS_xy / (self.SS_xx * self.SS_yy) ** (1/2)\n",
        "        self.t_r = self.r * ((self.n - 2) / (1 - self.r ** 2)) * (1/2)\n",
        "        self.pval_r = t.sf(abs(self.t_r), df = self.n - 2) * 2\n",
        "\n",
        "        ##\n",
        "        # Hypothesis test on the significant of regression (two-tailed T-test):\n",
        "        #\n",
        "        self.ANOVA()\n",
        "        self.F = (self.SS_R / 1) / (self.SS_E / (self.n - 2))\n",
        "        self.pval_F = f.sf(self.F, 1, self.n - 2)\n",
        "        pass\n",
        "\n",
        "    def compute_intervals(self, level: float = 0.95):\n",
        "        \"\"\"\n",
        "        Compute the confidence intervals and the prediction intervals:\n",
        "        \"\"\"\n",
        "        self.level = level\n",
        "        t_c = t.ppf(self.level, df = self.n - 2)\n",
        "\n",
        "        ##\n",
        "        # Confidence interval for the parameters:\n",
        "        #\n",
        "        self.b0_hat_lwr = self.b0_hat - t_c * self.se_b0_hat\n",
        "        self.b0_hat_upr = self.b0_hat + t_c * self.se_b0_hat\n",
        "\n",
        "        self.b1_hat_lwr = self.b1_hat - t_c * self.se_b1_hat\n",
        "        self.b1_hat_upr = self.b1_hat + t_c * self.se_b1_hat\n",
        "\n",
        "        ##\n",
        "        # Confidence interval of mean response at x:\n",
        "        #\n",
        "        self.func = lambda x: self.b0_hat + self.b1_hat * x\n",
        "        self.yhat_CI_lwr = lambda x: self.b0_hat + self.b1_hat * x - \\\n",
        "            t_c * np.sqrt(self.se * (1/self.n + (x - self.x_bar)**2/(self.SS_xx)))\n",
        "        self.yhat_CI_upr = lambda x: self.b0_hat + self.b1_hat * x + \\\n",
        "            t_c * np.sqrt(self.se * (1/self.n + (x - self.x_bar)**2/(self.SS_xx)))\n",
        "\n",
        "        ##\n",
        "        # Prediction interval of mean response at x:\n",
        "        #\n",
        "        self.yhat_PI_lwr = lambda x: self.b0_hat + self.b1_hat * x - \\\n",
        "            t_c * np.sqrt(self.se * (1 + 1/self.n + (x - self.x_bar)**2/(self.SS_xx)))\n",
        "        self.yhat_PI_upr = lambda x: self.b0_hat + self.b1_hat * x + \\\n",
        "            t_c * np.sqrt(self.se * (1 + 1/self.n + (x - self.x_bar)**2/(self.SS_xx)))\n",
        "        pass\n",
        "\n",
        "    def visualize(self):\n",
        "        \"\"\"\n",
        "        Visualize the entire analysis process:\n",
        "        \"\"\"\n",
        "\n",
        "        ##\n",
        "        # Visualize the loaded data:\n",
        "        #\n",
        "        fig, axs = plt.subplots(1, 2, figsize = (8,4), dpi = 100)\n",
        "        self.nbins = (max(self.X) - min(self.X)) * (self.n ** (1/3)) /(3.49 * np.std(self.X))\n",
        "        sns.histplot(self.X, bins = int(self.nbins), ax = axs[0])\n",
        "        axs[0].set_title(f\"Histogram of {self.predictor}\")\n",
        "        axs[0].grid(True)\n",
        "\n",
        "        self.nbins = (max(self.Y) - min(self.Y)) * (self.n ** (1/3)) /(3.49 * np.std(self.Y))\n",
        "        sns.histplot(self.Y, bins = int(self.nbins), ax = axs[1])\n",
        "        axs[1].set_title(f\"Histogram of {self.response}\")\n",
        "        axs[1].grid(True)\n",
        "        fig.tight_layout()\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3, figsize = (15,4), dpi = 100)\n",
        "        ##\n",
        "        # Visualize the regression analysis:\n",
        "        #\n",
        "        sns.scatterplot({f\"{self.predictor}\": self.X, f\"{self.response}\": self.Y},\n",
        "                        x =  f\"{self.predictor}\", y = f\"{self.response}\", ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.func(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'solid', linewidth = 1.0, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_CI_lwr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dashdot', linewidth = 0.75, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_CI_upr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dashdot', linewidth = 0.75, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_PI_lwr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dotted', linewidth = 0.55, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_PI_upr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dotted', linewidth = 0.55, ax = axs[0])\n",
        "        axs[0].set_title(f\"{self.response} vs. {self.predictor}\")\n",
        "        axs[0].grid(True)\n",
        "\n",
        "        ##\n",
        "        # Visualize the residual analysis:\n",
        "        #\n",
        "        sns.scatterplot({f\"{self.response}\": self.Y, \"Residual\": self.e},\n",
        "                        x = f\"{self.response}\", y = \"Residual\",\n",
        "                        ax = axs[1])\n",
        "        axs[1].axhline(y = 0, color = 'red', linestyle = 'dashed', linewidth = 1.0)\n",
        "        axs[1].set_title(f\"Residual Plot\")\n",
        "        axs[1].grid(True)\n",
        "\n",
        "        self.rank = np.array([(i - 0.375) / (self.n + 0.25) for i in range(1, self.n + 1)])\n",
        "        self.z_e = np.array([norm.ppf(i) for i in self.rank])\n",
        "        # self.e_z = np.array([z * self.se for z in self.z_e])\n",
        "        sns.scatterplot({\"Orderd Residual\": sorted(self.e), \"Z-score\": self.z_e},\n",
        "                        x = \"Orderd Residual\", y = \"Z-score\", ax = axs[2])\n",
        "        # sns.lineplot({\"Hypothetical Residual\": self.e_z, \"Z-score\": self.z_e},\n",
        "        #                 x = \"Hypothetical Residual\", y = \"Z-score\", ax = axs[2])\n",
        "        axs[2].set_title(f\"Residual Normality Plot\")\n",
        "        axs[2].grid(True)\n",
        "        fig.tight_layout()\n",
        "\n",
        "        pass\n",
        "\n",
        "    def rounding_values(self):\n",
        "        \"\"\"\n",
        "        Round all computed parameters (slope, intercept, standard errors, etc.) to four decimal places.\n",
        "        \"\"\"\n",
        "        self.e_stde = round(self.se ** (1/2), 4)\n",
        "        self.e_min = round(np.min(self.e), 4)\n",
        "        self.e_max = round(np.max(self.e), 4)\n",
        "        self.e_q1 = round(np.quantile(self.e, .25), 4)\n",
        "        self.e_q2 = round(np.median(self.e), 4)\n",
        "        self.e_q3 = round(np.quantile(self.e, .25), 4)\n",
        "\n",
        "        self.b0_hat = round(self.b0_hat, 4)\n",
        "        self.b0_hat_lwr = round(self.b0_hat_lwr, 4)\n",
        "        self.b0_hat_upr = round(self.b0_hat_upr, 4)\n",
        "        self.se_b0_hat = round(self.se_b0_hat, 4)\n",
        "        self.t_b0_hat = round(self.t_b0_hat, 4)\n",
        "\n",
        "        self.b1_hat = round(self.b1_hat, 4)\n",
        "        self.se_b1_hat = round(self.se_b1_hat, 4)\n",
        "        self.b1_hat_lwr = round(self.b1_hat_lwr, 4)\n",
        "        self.b1_hat_upr = round(self.b1_hat_upr, 4)\n",
        "        self.t_b1_hat = round(self.t_b1_hat, 4)\n",
        "\n",
        "        self.Rsquare = round(self.Rsquare, 4)\n",
        "        self.r = round(self.r, 4)\n",
        "        self.F = round(self.F, 4)\n",
        "        pass\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"\n",
        "        Generate a full analysis report.\n",
        "        \"\"\"\n",
        "        self.load_data()\n",
        "        self.fit()\n",
        "        self.compute_standard_error()\n",
        "        self.ANOVA()\n",
        "        self.hypothesis_test()\n",
        "        self.compute_intervals()\n",
        "        self.rounding_values()\n",
        "\n",
        "        ##\n",
        "        # Generate a report:\n",
        "        #\n",
        "        print(f\"\\nModel: {self.response} ~ {self.predictor}\")\n",
        "        print(f\"\\n\\t  Min \\t Q1 \\t Median \\t Q3 \\tMax\")\n",
        "        print(f\"Residuals: {self.e_min} \\t {self.e_q1} \\t {self.e_q2} \\t {self.e_q3} \\t {self.e_max}\")\n",
        "\n",
        "        print(f\"\\n\\t  Coefficient \\t Std. Error \\t 2.5% \\t 97.5% \\t t-Statistic \\t Pr(>|t|) at {100 * self.level}%\")\n",
        "        print(f\"Intercept: {self.b0_hat} \\t {self.se_b0_hat} \\t {self.b0_hat_lwr} \\t {self.b0_hat_upr} \\t {self.t_b0_hat} \\t {self.pval_b0}\")\n",
        "        print(f\"{self.predictor}: {self.b1_hat} \\t {self.se_b1_hat} \\t {self.b1_hat_lwr} \\t {self.b1_hat_upr} \\t {self.t_b1_hat} \\t {self.pval_b1}\")\n",
        "\n",
        "        print(f\"\\nResidual Std. Error: {self.e_stde } on {self.df} DF\")\n",
        "        print(f\"R-square: {self.Rsquare}\")\n",
        "        print(f\"Pearson correlation coef.: {self.r}, p-value: {self.pval_r}\")\n",
        "        print(f\"F-statistic: {self.F} on 1 predictor and {self.df} DF, p-value: {self.pval_F}\")\n",
        "\n",
        "        self.visualize()\n",
        "\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "g95BKXbqpHhX",
        "outputId": "5b9ffd04-ae07-4ecf-ff27-6e9de0d5bd11"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-53383e7787d5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mslr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dataset/TAMPALMS.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Market_Val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sale_Price\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mslr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-c9632cfdd756>\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mGenerate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfull\u001b[0m \u001b[0manalysis\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_standard_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c9632cfdd756>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mLoad\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m \u001b[0mfile\u001b[0m \u001b[0musing\u001b[0m \u001b[0mPandas\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \"\"\"\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/TAMPALMS.csv'"
          ]
        }
      ],
      "source": [
        "slr = SLR(\"./dataset/TAMPALMS.csv\", \"Market_Val\", \"Sale_Price\")\n",
        "slr.summary()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}