{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Q6zBs096pHhT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pandas._config.config.option_context at 0x239234becd0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import t, f, norm\n",
        "np.set_printoptions(precision= 5)\n",
        "pd.option_context('mode.use_inf_as_na', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lu8wI3zxpHhV"
      },
      "outputs": [],
      "source": [
        "class SLR():\n",
        "    \"\"\"\n",
        "    Author: Lucius Vo <https://github.com/vohuynhquangnguyen>\n",
        "    Construct a simple linear regression (SLR) model and conduct required estimations and hypothesis test.\n",
        "    Methods of estimating the model's parameters and hypothesis test are based on Mendenhall and Sincich (2013, p.96-165).\n",
        "\n",
        "    References:\n",
        "    1. Mendenhall, William, Sincich, Terry T. A Second Course in Statistics - Regression Analysis (7th Edition). Pearson, 2013\n",
        "    2. Montgomery, Douglas C., Runger, George C. Applied Statistics and Probability for Engineer (7th Edition). Wiley, 2018\n",
        "    \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        super(SLR, self).__init__\n",
        "        pass\n",
        "\n",
        "    def load_data(self, src: str, X_header: str, Y_header: str):\n",
        "        \"\"\"\n",
        "        Load the dataset from a .csv file using Pandas file handler.\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(src)\n",
        "        self.X_header = X_header; self.Y_header = Y_header\n",
        "        self.X = np.array(df[X_header])\n",
        "        self.Y = np.array(df[Y_header])\n",
        "        pass\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Compute the parameters of the fitted model using the ordinary least square (OLS) method.\n",
        "        \"\"\"\n",
        "        self.Xbar = np.mean(self.X)\n",
        "        self.Ybar = np.mean(self.Y)\n",
        "\n",
        "        self.SS_xx = sum((np.power(x - self.Xbar, 2) for x in self.X))\n",
        "        self.SS_yy = sum((np.power(y - self.Ybar, 2) for y in self.Y))\n",
        "        self.SS_xy = sum(((x - self.Xbar) * (y - self.Ybar) for (x,y) in zip(self.X,self.Y)))\n",
        "\n",
        "        self.B1hat = self.SS_xy / self.SS_xx\n",
        "        self.B0hat = self.Ybar - self.B1hat * self.Xbar\n",
        "        pass\n",
        "\n",
        "    def estimate_variance_residuals(self):\n",
        "        \"\"\"\n",
        "        Estimate the variance of residuals\n",
        "        \"\"\"\n",
        "        self.e = np.array([y - (self.B0hat + self.B1hat * x) for (x,y) in zip(self.X, self.Y)])\n",
        "        self.SS_E = sum((np.power(y - (self.B0hat + self.B1hat * x), 2) for (x,y) in zip(self.X, self.Y)))\n",
        "        self.s2 = self.SS_E / (len(self.Y) - 2)\n",
        "        self.SE_B1hat = np.power(self.s2 / self.SS_xx, 1/2)\n",
        "        self.SE_B0hat = np.power(self.s2 * ( 1 / len(self.Y) + self.Xbar ** 2 / self.SS_xx), 1/2)\n",
        "        pass\n",
        "\n",
        "    def ANOVA(self):\n",
        "        \"\"\"\n",
        "        Conduct the analysis of variance (ANOVA) on the fitted model.\n",
        "        \"\"\"\n",
        "        self.SS_R = sum((np.power((self.B0hat + self.B1hat * x) - self.Ybar, 2) for x in self.X))\n",
        "        self.SS_T = self.SS_R + self.SS_E\n",
        "        self.Rsquare = self.SS_R / self.SS_T\n",
        "        pass\n",
        "\n",
        "    def conduct_statistical_inference(self, level: float = 0.95):\n",
        "        \"\"\"\n",
        "        Conduct the hypothesis tests on the fitted model at the significant level (default is 95%).\n",
        "        \"\"\"\n",
        "        self.level = level\n",
        "        self.estimate_variance_residuals()\n",
        "        self.ANOVA()\n",
        "\n",
        "        # Test on the estimated slope and intercept (two-tailed T-test):\n",
        "        t_c = t.ppf((1 - level)/2, df = len(self.Y) - 2)\n",
        "        self.T_B1hat = (self.B1hat - 0) / self.SE_B1hat\n",
        "        self.T_B0hat = (self.B0hat - 0) / self.SE_B0hat\n",
        "\n",
        "        self.pval_B1 = t.sf(abs(self.T_B1hat), len(self.Y) - 2) * 2\n",
        "        self.pval_B0 = t.sf(abs(self.T_B0hat), len(self.Y) - 2) * 2\n",
        "\n",
        "        # Test on the Pearson correlation coefficient (two-tailed T-test):\n",
        "        self.r = np.power(self.SS_xy / (self.SS_xx * self.SS_yy), 1/2)\n",
        "        self.t_r = np.power(self.r * ((len(self.Y) - 2) / (1 - self.r ** 2)), 1/2)\n",
        "        self.pval_r = t.sf(abs(self.t_r), df = len(self.Y) - 2) * 2\n",
        "\n",
        "        # Test on the significant of regression (two-tailed T-test):\n",
        "        self.F = (self.SS_R / 1) / (self.SS_E / (len(self.Y) - 2))\n",
        "        self.pval_F = f.sf(self.F, 1, len(self.Y) - 2)\n",
        "        pass\n",
        "\n",
        "    def compute_intervals(self, level: float = 0.95):\n",
        "        \"\"\"\n",
        "        Compute the confidence intervals and the prediction intervals:\n",
        "        \"\"\"\n",
        "        t_c = t.ppf((1 - level)/2, df = len(self.Y) - 2)\n",
        "\n",
        "        # Confidence interval for the parameters:\n",
        "        self.B0hat_CI_lwr = self.B0hat - t_c * self.SE_B0hat\n",
        "        self.B0hat_CI_upr = self.B0hat + t_c * self.SE_B0hat\n",
        "\n",
        "        self.B1hat_CI_lwr = self.B1hat - t_c * self.SE_B1hat\n",
        "        self.B1hat_CI_upr = self.B1hat + t_c * self.SE_B1hat\n",
        "\n",
        "        # Confidence interval of mean response at x:\n",
        "        self.func = lambda x: self.B0hat + self.B1hat * x\n",
        "        self.Yhat_CI_lwr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x - t_c * np.sqrt(self.s2 * (1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "        self.Yhat_CI_upr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x + t_c * np.sqrt(self.s2 * (1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "\n",
        "        # Prediction interval of mean response at x:\n",
        "        self.yhat_PI_lwr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x - t_c * np.sqrt(self.s2 * (1 + 1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "        self.yhat_PI_upr = lambda x: \\\n",
        "          self.B0hat + self.B1hat * x + t_c * np.sqrt(self.s2 * (1 + 1/len(self.Y) + np.power(x - self.Xbar,2) / (self.SS_xx)))\n",
        "        pass\n",
        "\n",
        "    def visualize(self):\n",
        "        \"\"\"\n",
        "        Visualize the entire analysis process:\n",
        "        \"\"\"\n",
        "\n",
        "        # Visualize the distribution of the dataset:\n",
        "        fig, axs = plt.subplots(1, 2, figsize = (8,4), dpi = 100)\n",
        "        nbins = \\\n",
        "         (np.max(self.X) - np.min(self.X)) * np.power(len(self.Y), 1/3) / (3.49 * np.std(self.X, ddof= 1))\n",
        "        sns.histplot(self.X, bins = int(nbins), ax = axs[0])\n",
        "        axs[0].set_title(f\"Histogram of {self.X_header}\")\n",
        "        axs[0].grid(True)\n",
        "\n",
        "        nbins = \\\n",
        "         (np.max(self.Y) - np.min(self.Y)) * np.power(len(self.Y), 1/3) / (3.49 * np.std(self.Y, ddof= 1))\n",
        "        sns.histplot(self.Y, bins = int(nbins), ax = axs[1])\n",
        "        axs[1].set_title(f\"Histogram of {self.Y_header}\")\n",
        "        axs[1].grid(True)\n",
        "        fig.tight_layout()\n",
        "\n",
        "        # Visualize the regression analysis:\n",
        "        fig, axs = plt.subplots(1, 3, figsize = (15,4), dpi = 100)\n",
        "        sns.scatterplot({f\"{self.X_header}\": self.X, f\"{self.Y_header}\": self.Y},\n",
        "                        x =  f\"{self.X_header}\", y = f\"{self.Y_header}\", ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.func(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'solid', linewidth = 1.0, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.Yhat_CI_lwr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dashdot', linewidth = 0.75, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.Yhat_CI_upr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dashdot', linewidth = 0.75, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_PI_lwr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dotted', linewidth = 0.55, ax = axs[0])\n",
        "        sns.lineplot({\"x\": self.X, \"y\": self.yhat_PI_upr(self.X)},\n",
        "                     x = \"x\", y = \"y\", color = 'red', linestyle = 'dotted', linewidth = 0.55, ax = axs[0])\n",
        "        axs[0].set_title(f\"{self.Y_header} vs. {self.X_header}\")\n",
        "        axs[0].grid(True)\n",
        "\n",
        "        # Visualize the residual analysis:\n",
        "        sns.scatterplot({f\"{self.Y_header}\": self.Y, \"Residual\": self.e},\n",
        "                        x = f\"{self.Y_header}\", y = \"Residual\",\n",
        "                        ax = axs[1])\n",
        "        axs[1].axhline(y = 0, color = 'red', linestyle = 'dashed', linewidth = 1.0)\n",
        "        axs[1].set_title(f\"Residual Plot\")\n",
        "        axs[1].grid(True)\n",
        "\n",
        "        rank = np.array([(i - 0.375) / (len(self.Y) + 0.25) for i in range(1, len(self.Y) + 1)])\n",
        "        z_e = np.array([norm.ppf(i) for i in rank])\n",
        "        sns.scatterplot({\"Residual\": sorted(self.e), \"Z-score\": z_e},\n",
        "                        x = \"Residual\", y = \"Z-score\", ax = axs[2])\n",
        "        axs[2].set_title(f\"Residual Normality Plot\")\n",
        "        axs[2].grid(True)\n",
        "        fig.tight_layout()\n",
        "        pass\n",
        "\n",
        "    def generate_report(self):\n",
        "        \"\"\"\n",
        "        Generate a regression analysis report.\n",
        "        \"\"\"\n",
        "        print(f\"\\nModel: {self.Y_header} ~ {self.X_header}\")\n",
        "        print(f\"\\n\\t  Min \\t Q1 \\t Median \\t Q3 \\tMax\")\n",
        "        print(f\"Residuals: {np.min(self.e)} \\t {np.quantile(self.e, 0.25)} \\t {np.median(self.e)} \\t {np.quantile(self.e, 0.75)} \\t {np.max(self.e)}\")\n",
        "\n",
        "        print(f\"\\n\\t  Coefficient \\t Std. Error \\t Lower-bound CI \\t Upper-bound CI \\t t-Statistic \\t Pr(>|t|) at {100 * self.level}%\")\n",
        "        print(f\"Intercept: {self.B0hat} \\t {self.SE_B0hat} \\t {self.B0hat_CI_lwr} \\t {self.B0hat_CI_upr} \\t {self.T_B0hat} \\t {self.pval_B0}\")\n",
        "        print(f\"{self.X_header}: {self.B1hat} \\t {self.SE_B1hat} \\t {self.B1hat_CI_lwr} \\t {self.B1hat_CI_upr} \\t {self.T_B1hat} \\t {self.pval_B1}\")\n",
        "\n",
        "        print(f\"\\nResidual Std. Error: {np.power(self.s2,1/2)} on {len(self.Y) - 2} DF\")\n",
        "        print(f\"R-square: {self.Rsquare}\")\n",
        "        print(f\"Pearson correlation coef.: {self.r}, p-value: {self.pval_r}\")\n",
        "        print(f\"F-statistic: {self.F} on 1 predictor and {len(self.Y) - 2} DF, p-value: {self.pval_F}\")\n",
        "        pass\n",
        "\n",
        "    def run_regression_analysis(self):\n",
        "        \"\"\"\n",
        "        Generate a full analysis report.\n",
        "        \"\"\"\n",
        "\n",
        "        self.fit()\n",
        "        self.estimate_variance_residuals()\n",
        "        self.conduct_statistical_inference()\n",
        "        self.compute_intervals()\n",
        "        self.visualize()\n",
        "\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "g95BKXbqpHhX",
        "outputId": "a9f723d4-1f8b-4c31-adea-cfb4f8c5280b"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'axis' is an invalid keyword argument for sum()",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m slr \u001b[38;5;241m=\u001b[39m SLR()\n\u001b[0;32m      2\u001b[0m slr\u001b[38;5;241m.\u001b[39mload_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dataset/TAMPALMS.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarket_Val\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSale_Price\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m slr\u001b[38;5;241m.\u001b[39mrun_regression_analysis()\n",
            "Cell \u001b[1;32mIn[27], line 193\u001b[0m, in \u001b[0;36mSLR.run_regression_analysis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_variance_residuals()\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconduct_statistical_inference()\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_intervals()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisualize()\n",
            "Cell \u001b[1;32mIn[27], line 67\u001b[0m, in \u001b[0;36mSLR.conduct_statistical_inference\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m=\u001b[39m level\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_variance_residuals()\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mANOVA()\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Test on the estimated slope and intercept (two-tailed T-test):\u001b[39;00m\n\u001b[0;32m     70\u001b[0m t_c \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mppf((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m level)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
            "Cell \u001b[1;32mIn[27], line 55\u001b[0m, in \u001b[0;36mSLR.ANOVA\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mANOVA\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    Conduct the analysis of variance (ANOVA) on the fitted model.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSS_R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((np\u001b[38;5;241m.\u001b[39mpower((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB0hat \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB1hat \u001b[38;5;241m*\u001b[39m x) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mYbar, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX),\n\u001b[0;32m     56\u001b[0m                        axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSS_T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSS_R \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSS_E\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRsquare \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSS_R \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSS_T\n",
            "\u001b[1;31mTypeError\u001b[0m: 'axis' is an invalid keyword argument for sum()"
          ]
        }
      ],
      "source": [
        "slr = SLR()\n",
        "slr.load_data(\"./dataset/TAMPALMS.csv\", \"Market_Val\", \"Sale_Price\")\n",
        "slr.run_regression_analysis()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
